#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆæ•°æ®é›†ç®¡ç†å·¥å…·
æ”¯æŒdataset_builder.pyçš„æºæ•°æ®ç»“æ„ï¼ˆcfgæ–‡ä»¶ + å­”ä½å›¾ç‰‡ï¼‰
æ”¯æŒä»cfgæºæ•°æ®æŒ‰æ¯”ä¾‹åŒæ­¥åˆ°train/test/valï¼Œä¿æŒæ¯”ä¾‹å¹³è¡¡å’Œå»é‡
"""

import os
import shutil
import yaml
import argparse
import json
from pathlib import Path
from collections import defaultdict, Counter
import random
from PIL import Image
import numpy as np
from datetime import datetime

class EnhancedDatasetManager:
    def __init__(self, dataset_path="bioast_dataset"):
        self.dataset_path = Path(dataset_path)
        self.splits = ['train', 'test', 'val']
        self.classes = ['positive', 'negative']
        
        # å›¾ç‰‡å“ˆå¸Œç¼“å­˜
        self.image_hashes = {}
        self.duplicate_groups = []
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = self._get_current_stats()
    
    def _get_current_stats(self):
        """è·å–å½“å‰æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        stats = defaultdict(dict)
        total_count = 0
        
        for class_name in self.classes:
            class_total = 0
            for split in self.splits:
                split_path = self.dataset_path / class_name / split
                if split_path.exists():
                    count = len(list(split_path.glob("*.png")))
                    stats[class_name][split] = count
                    class_total += count
                    total_count += count
                else:
                    stats[class_name][split] = 0
            stats[class_name]['total'] = class_total
        
        stats['total'] = total_count
        return dict(stats)
    
    def get_current_split_ratios(self):
        """è·å–å½“å‰æ•°æ®é›†çš„åˆ†å‰²æ¯”ä¾‹"""
        total = self.stats['total']
        if total == 0:
            # é»˜è®¤æ¯”ä¾‹
            return {'train': 0.7, 'test': 0.2, 'val': 0.1}
        
        ratios = {}
        for split in self.splits:
            split_total = sum(self.stats[class_name][split] for class_name in self.classes)
            ratios[split] = split_total / total if total > 0 else 0
        
        return ratios
    
    def get_current_class_ratios(self):
        """è·å–å½“å‰æ•°æ®é›†çš„ç±»åˆ«æ¯”ä¾‹"""
        total = self.stats['total']
        if total == 0:
            return {'positive': 0.5, 'negative': 0.5}
        
        pos_total = self.stats['positive']['total']
        neg_total = self.stats['negative']['total']
        
        return {
            'positive': pos_total / total if total > 0 else 0.5,
            'negative': neg_total / total if total > 0 else 0.5
        }
    
    def print_stats(self):
        """æ‰“å°å½“å‰ç»Ÿè®¡ä¿¡æ¯"""
        print("ğŸ“Š å½“å‰æ•°æ®é›†ç»Ÿè®¡:")
        print("=" * 50)
        
        # æ‰“å°å„ç±»åˆ«å’Œåˆ†å‰²çš„ç»Ÿè®¡
        for class_name in self.classes:
            print(f"\n{class_name.upper()}:")
            for split in self.splits:
                count = self.stats[class_name][split]
                print(f"  {split}: {count}")
            print(f"  æ€»è®¡: {self.stats[class_name]['total']}")
        
        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        total = self.stats['total']
        if total > 0:
            pos_ratio = self.stats['positive']['total'] / total * 100
            print(f"\næ€»è®¡: {total}")
            print(f"ç±»åˆ«æ¯”ä¾‹: {pos_ratio:.1f}% positive, {100-pos_ratio:.1f}% negative")
            
            # æ‰“å°åˆ†å‰²æ¯”ä¾‹
            print("åˆ†å‰²æ¯”ä¾‹:")
            for split in self.splits:
                split_total = sum(self.stats[class_name][split] for class_name in self.classes)
                split_ratio = split_total / total * 100 if total > 0 else 0
                print(f"  {split}: {split_total} ({split_ratio:.1f}%)")
        else:
            print("\næ•°æ®é›†ä¸ºç©º")
    
    def calculate_image_hash(self, image_path):
        """è®¡ç®—å›¾ç‰‡çš„æ„ŸçŸ¥å“ˆå¸Œ"""
        try:
            with Image.open(image_path) as img:
                # è½¬æ¢ä¸ºç°åº¦å¹¶è°ƒæ•´å¤§å°
                img = img.convert('L').resize((8, 8))
                # è®¡ç®—åƒç´ å¹³å‡å€¼
                pixels = np.array(img)
                avg = pixels.mean()
                # ç”Ÿæˆå“ˆå¸Œ
                hash_bits = pixels > avg
                hash_str = ''.join(['1' if b else '0' for b in hash_bits.flatten()])
                return hash_str
        except Exception:
            return None
    
    def parse_cfg_file(self, cfg_path):
        """è§£æcfgæ–‡ä»¶è·å–é˜´é˜³æ€§æ ‡ç­¾"""
        try:
            with open(cfg_path, 'r', encoding='utf-8') as f:
                line = f.readline().strip()
                
            # æ ¼å¼ï¼šæ–‡ä»¶å,æ ‡ç­¾å­—ç¬¦ä¸²
            parts = line.split(',')
            if len(parts) != 2:
                print(f"è­¦å‘Š: cfgæ–‡ä»¶æ ¼å¼å¼‚å¸¸: {cfg_path}")
                return None
                
            filename = parts[0]
            labels_str = parts[1]
            
            # è§£ææ ‡ç­¾å­—ç¬¦ä¸²ï¼Œ+è¡¨ç¤ºé˜³æ€§ï¼Œ-è¡¨ç¤ºé˜´æ€§
            # cfgç´¢å¼•iç›´æ¥å¯¹åº”hole_{i}.png
            labels = []
            for i, char in enumerate(labels_str):
                hole_num = i  # cfgç´¢å¼•iç›´æ¥å¯¹åº”hole_{i}.png
                # åªå¤„ç†å­˜åœ¨çš„å›¾ç‰‡æ–‡ä»¶ï¼ˆhole_24åˆ°hole_119ï¼‰
                if 24 <= hole_num <= 119:
                    if char == '+':
                        labels.append((hole_num, 'positive'))
                    elif char == '-':
                        labels.append((hole_num, 'negative'))
                    # å¿½ç•¥å…¶ä»–å­—ç¬¦
                        
            return {
                'filename': filename,
                'labels': labels,
                'sample_name': filename.replace('.bmp', '')
            }
            
        except Exception as e:
            print(f"é”™è¯¯: æ— æ³•è§£æcfgæ–‡ä»¶ {cfg_path}: {e}")
            return None
    
    def load_existing_hashes(self):
        """åŠ è½½ç°æœ‰æ•°æ®é›†çš„å›¾ç‰‡å“ˆå¸Œ"""
        print("ğŸ” æ‰«æç°æœ‰æ•°æ®é›†å›¾ç‰‡...")
        self.image_hashes.clear()
        
        total_images = 0
        for class_name in self.classes:
            for split in self.splits:
                split_path = self.dataset_path / class_name / split
                if split_path.exists():
                    for img_file in split_path.glob("*.png"):
                        img_hash = self.calculate_image_hash(img_file)
                        if img_hash:
                            self.image_hashes[str(img_file)] = img_hash
                            total_images += 1
        
        print(f"âœ… åŠ è½½äº† {total_images} å¼ ç°æœ‰å›¾ç‰‡çš„å“ˆå¸Œ")
        return total_images
    
    def sync_from_cfg_source(self, source_dir, preserve_class_ratio=True, preserve_split_ratio=True, split_ratio=None):
        """ä»cfgæºæ•°æ®æŒ‰æ¯”ä¾‹åŒæ­¥å›¾ç‰‡åˆ°å„ä¸ªåˆ†å‰²
        
        Args:
            source_dir: æºæ•°æ®ç›®å½•ï¼ˆåŒ…å«cfgæ–‡ä»¶å’ŒåŒåå­ç›®å½•ï¼‰
            preserve_class_ratio: æ˜¯å¦ä¿æŒç°æœ‰çš„é˜´é˜³æ€§æ¯”ä¾‹
            preserve_split_ratio: æ˜¯å¦ä¿æŒç°æœ‰çš„train/test/valåˆ†å‰²æ¯”ä¾‹
            split_ratio: è‡ªå®šä¹‰åˆ†å‰²æ¯”ä¾‹ {'train': 0.7, 'test': 0.2, 'val': 0.1}
        """
        print("ğŸ”„ ä»cfgæºæ•°æ®æŒ‰æ¯”ä¾‹åŒæ­¥å›¾ç‰‡...")
        source_path = Path(source_dir)
        
        if not source_path.exists():
            print(f"âŒ æºç›®å½•ä¸å­˜åœ¨: {source_path}")
            return
        
        # åŠ è½½ç°æœ‰å›¾ç‰‡å“ˆå¸Œ
        self.load_existing_hashes()
        
        # è·å–å½“å‰æ¯”ä¾‹
        current_stats = self._get_current_stats()
        current_class_ratios = self.get_current_class_ratios()
        
        if preserve_split_ratio:
            current_split_ratios = self.get_current_split_ratios()
        else:
            current_split_ratios = split_ratio or {'train': 0.7, 'test': 0.2, 'val': 0.1}
        
        total_current = current_stats['total']
        print(f"ğŸ“Š å½“å‰æ•°æ®é›†: {total_current} å¼ å›¾ç‰‡")
        print(f"   ç±»åˆ«æ¯”ä¾‹: positive={current_class_ratios['positive']:.3f}, negative={current_class_ratios['negative']:.3f}")
        print(f"   åˆ†å‰²æ¯”ä¾‹: train={current_split_ratios['train']:.3f}, test={current_split_ratios['test']:.3f}, val={current_split_ratios['val']:.3f}")
        
        # æ‰«æcfgæ–‡ä»¶
        cfg_files = list(source_path.glob("*.cfg"))
        print(f"ğŸ” å‘ç° {len(cfg_files)} ä¸ªcfgæ–‡ä»¶")
        
        samples_data = []
        for cfg_file in cfg_files:
            cfg_data = self.parse_cfg_file(cfg_file)
            if cfg_data:
                # æ£€æŸ¥å¯¹åº”çš„å›¾ç‰‡ç›®å½•æ˜¯å¦å­˜åœ¨
                sample_dir = source_path / cfg_data['sample_name']
                if sample_dir.exists():
                    cfg_data['sample_dir'] = sample_dir
                    samples_data.append(cfg_data)
                    print(f"âœ… åŠ è½½æ ·æœ¬: {cfg_data['sample_name']}, å­”ä½æ•°: {len(cfg_data['labels'])}")
                else:
                    print(f"âš ï¸  æœªæ‰¾åˆ°å¯¹åº”å›¾ç‰‡ç›®å½•: {sample_dir}")
        
        if not samples_data:
            print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„æ ·æœ¬æ•°æ®")
            return
        
        # æ”¶é›†æ‰€æœ‰å›¾ç‰‡åŠå…¶æ ‡ç­¾
        new_positive_images = []
        new_negative_images = []
        duplicate_count = 0
        
        for sample in samples_data:
            sample_dir = sample['sample_dir']
            
            for hole_num, label in sample['labels']:
                hole_file = sample_dir / f"hole_{hole_num}.png"
                
                if hole_file.exists():
                    # è®¡ç®—å›¾ç‰‡å“ˆå¸Œæ£€æŸ¥é‡å¤
                    img_hash = self.calculate_image_hash(hole_file)
                    if not img_hash:
                        continue
                
                    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                    is_duplicate = False
                    for existing_path, existing_hash in self.image_hashes.items():
                        if img_hash == existing_hash:
                            duplicate_count += 1
                            is_duplicate = True
                            break
                    
                    if not is_duplicate:
                        image_info = {
                            'path': hole_file,
                            'sample': sample['sample_name'],
                            'hole': hole_num,
                            'label': label,
                            'hash': img_hash
                        }
                        
                        if label == 'positive':
                            new_positive_images.append(image_info)
                        else:
                            new_negative_images.append(image_info)
        
        total_new = len(new_positive_images) + len(new_negative_images)
        print(f"ğŸ“‹ å‘ç° {total_new} å¼ æ–°å›¾ç‰‡")
        print(f"   é˜³æ€§: {len(new_positive_images)} å¼ ")
        print(f"   é˜´æ€§: {len(new_negative_images)} å¼ ")
        print(f"ğŸ“‹ è·³è¿‡ {duplicate_count} å¼ é‡å¤å›¾ç‰‡")
        
        if total_new == 0:
            print("âŒ æ²¡æœ‰æ–°å›¾ç‰‡å¯ä»¥æ·»åŠ ")
            return
        
        # æŒ‰ç±»åˆ«æ¯”ä¾‹é€‰æ‹©å›¾ç‰‡
        if preserve_class_ratio and total_current > 0:
            target_pos_count = int(total_new * current_class_ratios['positive'])
            target_neg_count = total_new - target_pos_count
            
            print(f"ğŸ“Š æŒ‰ç±»åˆ«æ¯”ä¾‹({current_class_ratios['positive']:.3f})é€‰æ‹©:")
            print(f"   ç›®æ ‡æ­£æ ·æœ¬: {target_pos_count}")
            print(f"   ç›®æ ‡è´Ÿæ ·æœ¬: {target_neg_count}")
            
            # éšæœºé€‰æ‹©
            random.shuffle(new_positive_images)
            random.shuffle(new_negative_images)
            
            selected_positive = new_positive_images[:target_pos_count] if len(new_positive_images) >= target_pos_count else new_positive_images
            selected_negative = new_negative_images[:target_neg_count] if len(new_negative_images) >= target_neg_count else new_negative_images
        else:
            # ä½¿ç”¨æ‰€æœ‰æ–°å›¾ç‰‡
            selected_positive = new_positive_images  
            selected_negative = new_negative_images
            print("ğŸ“Š ä½¿ç”¨æ‰€æœ‰æ–°å›¾ç‰‡")
        
        all_selected = selected_positive + selected_negative
        total_selected = len(all_selected)
        
        print(f"ğŸ“Š æœ€ç»ˆé€‰æ‹©: {len(selected_positive)} æ­£æ ·æœ¬, {len(selected_negative)} è´Ÿæ ·æœ¬ (æ€»è®¡{total_selected})")
        
        # æŒ‰åˆ†å‰²æ¯”ä¾‹åˆ†é…å›¾ç‰‡
        random.shuffle(all_selected)
        
        train_end = int(total_selected * current_split_ratios['train'])
        test_end = train_end + int(total_selected * current_split_ratios['test'])
        
        split_assignments = {
            'train': all_selected[:train_end],
            'test': all_selected[train_end:test_end],
            'val': all_selected[test_end:]
        }
        
        print(f"ğŸ“Š åˆ†å‰²åˆ†é…:")
        for split, images in split_assignments.items():
            pos_count = sum(1 for img in images if img['label'] == 'positive')
            neg_count = len(images) - pos_count
            print(f"   {split}: {len(images)} å¼  (æ­£æ ·æœ¬:{pos_count}, è´Ÿæ ·æœ¬:{neg_count})")
        
        # å¤åˆ¶å›¾ç‰‡åˆ°å„ä¸ªåˆ†å‰²
        total_added = 0
        split_added = defaultdict(lambda: defaultdict(int))
        
        for split, images in split_assignments.items():
            for img_info in images:
                target_dir = self.dataset_path / img_info['label'] / split
                target_dir.mkdir(parents=True, exist_ok=True)
                
                # ç”Ÿæˆå”¯ä¸€æ–‡ä»¶åï¼šæ ·æœ¬å_å­”ä½å·.png
                new_filename = f"{img_info['sample']}_hole_{img_info['hole']}.png"
                target_path = target_dir / new_filename
                
                # é¿å…æ–‡ä»¶åå†²çª
                counter = 1
                while target_path.exists():
                    stem = f"{img_info['sample']}_hole_{img_info['hole']}"
                    target_path = target_dir / f"{stem}_sync{counter}.png"
                    counter += 1
                
                try:
                    shutil.copy2(img_info['path'], target_path)
                    self.image_hashes[str(target_path)] = img_info['hash']
                    total_added += 1
                    split_added[split][img_info['label']] += 1
                    
                    if total_added <= 10:  # åªæ˜¾ç¤ºå‰10ä¸ª
                        print(f"âœ… æ·»åŠ : {img_info['sample']}_hole_{img_info['hole']} â†’ {img_info['label']}/{split}")
                    elif total_added == 11:
                        print("   ... (æ›´å¤šæ–‡ä»¶)")
                        
                except Exception as e:
                    print(f"âŒ å¤åˆ¶å¤±è´¥ {img_info['path']}: {e}")
        
        print(f"\nâœ… åŒæ­¥å®Œæˆï¼æ€»è®¡æ·»åŠ  {total_added} å¼ å›¾ç‰‡")
        for split in self.splits:
            pos_added = split_added[split]['positive']
            neg_added = split_added[split]['negative']
            split_total = pos_added + neg_added
            if split_total > 0:
                print(f"   {split}: {split_total} å¼  (æ­£:{pos_added}, è´Ÿ:{neg_added})")
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self.stats = self._get_current_stats()
        
        # æ˜¾ç¤ºæ›´æ–°åçš„ç»Ÿè®¡
        new_total = self.stats['total']
        new_class_ratios = self.get_current_class_ratios()
        new_split_ratios = self.get_current_split_ratios()
        
        print(f"\nğŸ“Š æ›´æ–°åæ•°æ®é›†: {new_total} å¼ å›¾ç‰‡")
        print(f"   ç±»åˆ«æ¯”ä¾‹: positive={new_class_ratios['positive']:.3f}, negative={new_class_ratios['negative']:.3f}")
        print(f"   åˆ†å‰²æ¯”ä¾‹: train={new_split_ratios['train']:.3f}, test={new_split_ratios['test']:.3f}, val={new_split_ratios['val']:.3f}")
        
        return total_added
    
    def save_dataset_info(self):
        """ä¿å­˜æ•°æ®é›†ä¿¡æ¯(JSONæ ¼å¼)"""
        report_path = self.dataset_path / "dataset_stats.json"
        
        # å‡†å¤‡æŠ¥å‘Šæ•°æ®
        report_data = {
            "metadata": {
                "source_directory": "cfgæºæ•°æ®æŒ‰æ¯”ä¾‹åŒæ­¥",
                "output_directory": str(self.dataset_path),
                "sample_count": "N/A",
                "generation_time": datetime.now().isoformat(),
                "tool_version": "enhanced_dataset_manager.py"
            },
            "summary": {
                "positive_total": self.stats.get('positive', {}).get('total', 0),
                "negative_total": self.stats.get('negative', {}).get('total', 0),
                "total_samples": self.stats.get('total', 0)
            },
            "dataset_splits": {}
        }
        
        # æ·»åŠ å„æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯
        for subset in self.splits:
            pos_count = self.stats.get('positive', {}).get(subset, 0)
            neg_count = self.stats.get('negative', {}).get(subset, 0)
            total_count = pos_count + neg_count
            
            if total_count > 0:
                pos_ratio = pos_count / total_count
                neg_ratio = neg_count / total_count
                
                report_data["dataset_splits"][subset] = {
                    "positive": {
                        "count": pos_count,
                        "ratio": round(pos_ratio, 4)
                    },
                    "negative": {
                        "count": neg_count,
                        "ratio": round(neg_ratio, 4)
                    },
                    "total": total_count
                }
        
        # å†™å…¥JSONæ–‡ä»¶
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯å·²ä¿å­˜åˆ°: {report_path}")

def main():
    parser = argparse.ArgumentParser(description='å¢å¼ºç‰ˆæ•°æ®é›†ç®¡ç†å·¥å…·')
    parser.add_argument('--dataset', type=str, default='bioast_dataset', help='æ•°æ®é›†è·¯å¾„')
    
    subparsers = parser.add_subparsers(dest='command', help='å¯ç”¨å‘½ä»¤')
    
    # ç»Ÿè®¡å‘½ä»¤
    subparsers.add_parser('stats', help='æ˜¾ç¤ºæ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯')
    
    # ä»cfgæºåŒæ­¥æ•°æ®
    sync_parser = subparsers.add_parser('sync-from-cfg', help='ä»cfgæºæ•°æ®æŒ‰æ¯”ä¾‹åŒæ­¥å›¾ç‰‡åˆ°train/test/val')
    sync_parser.add_argument('--source', type=str, required=True, help='cfgæºæ•°æ®ç›®å½•')
    sync_parser.add_argument('--preserve-class-ratio', action='store_true', default=True, 
                            help='ä¿æŒç°æœ‰çš„é˜´é˜³æ€§æ¯”ä¾‹')
    sync_parser.add_argument('--preserve-split-ratio', action='store_true', default=True,
                            help='ä¿æŒç°æœ‰çš„train/test/valåˆ†å‰²æ¯”ä¾‹')
    sync_parser.add_argument('--train-ratio', type=float, default=0.7, help='è®­ç»ƒé›†æ¯”ä¾‹')
    sync_parser.add_argument('--test-ratio', type=float, default=0.2, help='æµ‹è¯•é›†æ¯”ä¾‹')
    sync_parser.add_argument('--val-ratio', type=float, default=0.1, help='éªŒè¯é›†æ¯”ä¾‹')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    manager = EnhancedDatasetManager(args.dataset)
    
    if args.command == 'stats':
        manager.print_stats()
        
    elif args.command == 'sync-from-cfg':
        # æ„å»ºè‡ªå®šä¹‰åˆ†å‰²æ¯”ä¾‹
        custom_split_ratio = None
        if not args.preserve_split_ratio:
            custom_split_ratio = {
                'train': args.train_ratio,
                'test': args.test_ratio,
                'val': args.val_ratio
            }
        
        added_count = manager.sync_from_cfg_source(
            source_dir=args.source,
            preserve_class_ratio=args.preserve_class_ratio,
            preserve_split_ratio=args.preserve_split_ratio,
            split_ratio=custom_split_ratio
        )
        
        if added_count > 0:
            manager.save_dataset_info()
            print(f"\nğŸ‰ åŒæ­¥å®Œæˆï¼æŒ‰æ¯”ä¾‹æ·»åŠ äº† {added_count} å¼ æ–°å›¾ç‰‡åˆ°train/test/val")
        else:
            print("\nâš ï¸  æ²¡æœ‰æ–°å›¾ç‰‡è¢«æ·»åŠ ")

if __name__ == "__main__":
    main()