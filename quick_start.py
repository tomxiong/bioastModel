#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
BioAstæ¨¡å‹ç®¡ç†ç³»ç»Ÿ - å¿«é€Ÿå¼€å§‹è„šæœ¬

è¿™ä¸ªè„šæœ¬æä¾›äº†ä¸€ä¸ªç®€å•çš„å‘½ä»¤è¡Œç•Œé¢ï¼Œè®©ç”¨æˆ·å¯ä»¥å¿«é€Ÿå¼€å§‹ä½¿ç”¨ç³»ç»Ÿã€‚

ä½¿ç”¨æ–¹æ³•:
    python quick_start.py                    # äº¤äº’å¼èœå•
    python quick_start.py train <model>      # è®­ç»ƒæŒ‡å®šæ¨¡å‹
    python quick_start.py list               # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
    python quick_start.py compare            # å¯¹æ¯”æ¨¡å‹
    python quick_start.py status             # æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€
"""

import sys
import os
import argparse
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from utils.integration import ModelLifecycleManager
    from utils.config import ConfigManager
except ImportError as e:
    print(f"âŒ å¯¼å…¥é”™è¯¯: {e}")
    print("è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–åŒ…: pip install -r requirements.txt")
    sys.exit(1)

def print_banner():
    """æ‰“å°ç³»ç»Ÿæ¨ªå¹…"""
    print("\n" + "="*60)
    print("ğŸ§¬ BioAstæ¨¡å‹ç®¡ç†ç³»ç»Ÿ - å¿«é€Ÿå¼€å§‹")
    print("="*60)
    print("ä¸“ä¸ºç”Ÿç‰©ä¿¡æ¯å­¦è®¾è®¡çš„æ¨¡å‹ç”Ÿå‘½å‘¨æœŸç®¡ç†å¹³å°")
    print("="*60 + "\n")

def check_environment():
    """æ£€æŸ¥ç¯å¢ƒé…ç½®"""
    print("ğŸ” æ£€æŸ¥ç¯å¢ƒé…ç½®...")
    
    # æ£€æŸ¥æ•°æ®ç›®å½•
    data_dirs = ['bioast_dataset', 'data', './bioast_dataset']
    data_dir = None
    for d in data_dirs:
        if os.path.exists(d):
            data_dir = d
            break
    
    if not data_dir:
        print("âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°æ•°æ®é›†ç›®å½•")
        print("è¯·ç¡®ä¿æ•°æ®é›†ä½äºä»¥ä¸‹ä½ç½®ä¹‹ä¸€:")
        for d in data_dirs:
            print(f"  - {d}")
        return False
    else:
        print(f"âœ… æ‰¾åˆ°æ•°æ®é›†: {data_dir}")
    
    # æ£€æŸ¥å¿…è¦ç›®å½•
    required_dirs = ['models', 'experiments', 'reports', 'logs']
    for dir_name in required_dirs:
        if not os.path.exists(dir_name):
            os.makedirs(dir_name, exist_ok=True)
            print(f"ğŸ“ åˆ›å»ºç›®å½•: {dir_name}")
    
    print("âœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ\n")
    return True

def get_available_models():
    """è·å–å¯ç”¨çš„æ¨¡å‹åˆ—è¡¨"""
    return {
        '1': {
            'name': 'efficientnet_b0',
            'display_name': 'EfficientNet-B0',
            'description': 'è½»é‡çº§é«˜æ•ˆæ¨¡å‹ï¼Œé€‚åˆå¿«é€Ÿè®­ç»ƒ'
        },
        '2': {
            'name': 'resnet18_improved',
            'display_name': 'ResNet18-Improved',
            'description': 'æ”¹è¿›ç‰ˆResNet18ï¼Œç¨³å®šå¯é '
        },
        '3': {
            'name': 'airbubble_hybrid_net',
            'display_name': 'AirBubble-HybridNet',
            'description': 'æ··åˆæ¶æ„ï¼Œä¸“ä¸ºèŒè½æ£€æµ‹ä¼˜åŒ–'
        },
        '4': {
            'name': 'micro_vit',
            'display_name': 'Micro-ViT',
            'description': 'å¾®å‹Vision Transformer'
        },
        '5': {
            'name': 'convnext_tiny',
            'display_name': 'ConvNeXt-Tiny',
            'description': 'ç°ä»£å·ç§¯ç½‘ç»œæ¶æ„'
        }
    }

def show_main_menu():
    """æ˜¾ç¤ºä¸»èœå•"""
    print("ğŸ¯ è¯·é€‰æ‹©æ“ä½œ:")
    print("1. è®­ç»ƒå•ä¸ªæ¨¡å‹")
    print("2. æŸ¥çœ‹æ‰€æœ‰æ¨¡å‹")
    print("3. æ¨¡å‹å¯¹æ¯”åˆ†æ")
    print("4. ç³»ç»ŸçŠ¶æ€")
    print("5. æ‰¹é‡è®­ç»ƒ")
    print("6. æ•°æ®é›†æ£€æŸ¥")
    print("7. ç”ŸæˆæŠ¥å‘Š")
    print("8. å¸®åŠ©æ–‡æ¡£")
    print("0. é€€å‡º")
    print("-" * 40)

def show_model_menu():
    """æ˜¾ç¤ºæ¨¡å‹é€‰æ‹©èœå•"""
    models = get_available_models()
    print("\nğŸ“‹ å¯ç”¨æ¨¡å‹:")
    for key, model in models.items():
        print(f"{key}. {model['display_name']} - {model['description']}")
    print("0. è¿”å›ä¸»èœå•")
    print("-" * 50)

def train_model_interactive():
    """äº¤äº’å¼è®­ç»ƒæ¨¡å‹"""
    show_model_menu()
    
    choice = input("è¯·é€‰æ‹©è¦è®­ç»ƒçš„æ¨¡å‹ (è¾“å…¥æ•°å­—): ").strip()
    
    if choice == '0':
        return
    
    models = get_available_models()
    if choice not in models:
        print("âŒ æ— æ•ˆé€‰æ‹©")
        return
    
    model_info = models[choice]
    model_name = model_info['name']
    
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ: {model_info['display_name']}")
    print(f"æè¿°: {model_info['description']}")
    
    # è¯¢é—®æ•°æ®é›†è·¯å¾„
    data_path = input("æ•°æ®é›†è·¯å¾„ (å›è½¦ä½¿ç”¨é»˜è®¤ 'bioast_dataset'): ").strip()
    if not data_path:
        data_path = 'bioast_dataset'
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        return
    
    # å¼€å§‹è®­ç»ƒ
    success = train_single_model(model_name, data_path)
    
    if success:
        print("\nâœ… è®­ç»ƒå®Œæˆï¼")
        input("æŒ‰å›è½¦é”®ç»§ç»­...")
    else:
        print("\nâŒ è®­ç»ƒå¤±è´¥")
        input("æŒ‰å›è½¦é”®ç»§ç»­...")

def train_single_model(model_name, data_path=None):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    try:
        # åˆå§‹åŒ–ç®¡ç†å™¨
        config = ConfigManager().get_default_config()
        manager = ModelLifecycleManager(config)
        manager.start_services()
        
        # æ¨¡å‹é…ç½®æ˜ å°„
        model_configs = {
            'efficientnet_b0': {
                'name': 'EfficientNet-B0',
                'description': 'è½»é‡çº§é«˜æ•ˆæ¨¡å‹',
                'model_type': 'classification',
                'algorithm': 'efficientnet_b0',
                'data_config': {
                    'data_path': data_path or 'bioast_dataset',
                    'image_size': (70, 70),
                    'batch_size': 32,
                    'test_size': 0.2
                },
                'training_config': {
                    'epochs': 50,
                    'learning_rate': 0.001,
                    'optimizer': 'adam'
                }
            },
            'resnet18_improved': {
                'name': 'ResNet18-Improved',
                'description': 'æ”¹è¿›ç‰ˆResNet18',
                'model_type': 'classification',
                'algorithm': 'resnet18_improved',
                'data_config': {
                    'data_path': data_path or 'bioast_dataset',
                    'image_size': (70, 70),
                    'batch_size': 32,
                    'test_size': 0.2
                },
                'training_config': {
                    'epochs': 50,
                    'learning_rate': 0.001,
                    'optimizer': 'adam'
                }
            },
            'airbubble_hybrid_net': {
                'name': 'AirBubble-HybridNet',
                'description': 'æ··åˆæ¶æ„èŒè½æ£€æµ‹æ¨¡å‹',
                'model_type': 'classification',
                'algorithm': 'airbubble_hybrid_net',
                'data_config': {
                    'data_path': data_path or 'bioast_dataset',
                    'image_size': (70, 70),
                    'batch_size': 32,
                    'test_size': 0.2
                },
                'training_config': {
                    'epochs': 50,
                    'learning_rate': 0.001,
                    'optimizer': 'adam'
                }
            },
            'micro_vit': {
                'name': 'Micro-ViT',
                'description': 'å¾®å‹Vision Transformer',
                'model_type': 'classification',
                'algorithm': 'micro_vit',
                'data_config': {
                    'data_path': data_path or 'bioast_dataset',
                    'image_size': (70, 70),
                    'batch_size': 16,
                    'test_size': 0.2
                },
                'training_config': {
                    'epochs': 50,
                    'learning_rate': 0.0001,
                    'optimizer': 'adamw'
                }
            },
            'convnext_tiny': {
                'name': 'ConvNeXt-Tiny',
                'description': 'ç°ä»£å·ç§¯ç½‘ç»œ',
                'model_type': 'classification',
                'algorithm': 'convnext_tiny',
                'data_config': {
                    'data_path': data_path or 'bioast_dataset',
                    'image_size': (70, 70),
                    'batch_size': 32,
                    'test_size': 0.2
                },
                'training_config': {
                    'epochs': 50,
                    'learning_rate': 0.001,
                    'optimizer': 'adamw'
                }
            }
        }
        
        if model_name not in model_configs:
            print(f"âŒ ä¸æ”¯æŒçš„æ¨¡å‹: {model_name}")
            return False
        
        model_config = model_configs[model_name]
        
        print(f"ğŸ“ æ¨¡å‹é…ç½®:")
        print(f"  åç§°: {model_config['name']}")
        print(f"  ç®—æ³•: {model_config['algorithm']}")
        print(f"  æ•°æ®è·¯å¾„: {model_config['data_config']['data_path']}")
        print(f"  è®­ç»ƒè½®æ•°: {model_config['training_config']['epochs']}")
        print(f"  å­¦ä¹ ç‡: {model_config['training_config']['learning_rate']}")
        
        # åˆ›å»ºè®­ç»ƒå·¥ä½œæµ
        print("\nğŸ”„ åˆ›å»ºè®­ç»ƒå·¥ä½œæµ...")
        workflow_id = manager.create_training_workflow(
            model_config=model_config,
            data_config=model_config['data_config'],
            training_config=model_config['training_config']
        )
        
        print(f"âœ… å·¥ä½œæµåˆ›å»ºæˆåŠŸ: {workflow_id}")
        
        # æ‰§è¡Œè®­ç»ƒ
        print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
        success = manager.execute_workflow(workflow_id)
        
        if success:
            print("\nâœ… è®­ç»ƒæˆåŠŸå®Œæˆï¼")
            
            # è·å–è®­ç»ƒç»“æœ
            workflow_status = manager.get_workflow_status(workflow_id)
            experiment_id = workflow_status.get('experiment_id')
            
            if experiment_id:
                # ç”ŸæˆæŠ¥å‘Š
                print("ğŸ“Š ç”Ÿæˆå®éªŒæŠ¥å‘Š...")
                report_path = manager.generate_experiment_report(
                    experiment_id=experiment_id,
                    output_format='html'
                )
                print(f"ğŸ“„ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
                
                # è·å–æ¨¡å‹ä¿¡æ¯
                models = manager.list_models()
                if models:
                    latest_model = models[-1]
                    print(f"\nğŸ¯ è®­ç»ƒç»“æœ:")
                    print(f"  æ¨¡å‹ID: {latest_model['id']}")
                    performance = latest_model.get('performance', {})
                    if performance:
                        for metric, value in performance.items():
                            print(f"  {metric}: {value}")
            
            return True
        else:
            print("\nâŒ è®­ç»ƒå¤±è´¥")
            return False
            
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        return False

def list_models():
    """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹"""
    try:
        config = ConfigManager().get_default_config()
        manager = ModelLifecycleManager(config)
        manager.start_services()
        
        models = manager.list_models()
        
        if not models:
            print("ğŸ“­ æš‚æ— è®­ç»ƒå¥½çš„æ¨¡å‹")
            return
        
        print(f"\nğŸ“‹ å·²è®­ç»ƒæ¨¡å‹ ({len(models)}ä¸ª):")
        print("-" * 80)
        print(f"{'åºå·':<4} {'æ¨¡å‹åç§°':<20} {'æ¨¡å‹ID':<15} {'å‡†ç¡®ç‡':<10} {'åˆ›å»ºæ—¶é—´':<20}")
        print("-" * 80)
        
        for i, model in enumerate(models, 1):
            performance = model.get('performance', {})
            accuracy = performance.get('accuracy', 'N/A')
            if isinstance(accuracy, float):
                accuracy = f"{accuracy:.4f}"
            
            created_at = model.get('created_at', 'N/A')
            if len(created_at) > 19:
                created_at = created_at[:19]
            
            print(f"{i:<4} {model['name']:<20} {model['id']:<15} {accuracy:<10} {created_at:<20}")
        
        print("-" * 80)
        
    except Exception as e:
        print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")

def compare_models_interactive():
    """äº¤äº’å¼æ¨¡å‹å¯¹æ¯”"""
    try:
        config = ConfigManager().get_default_config()
        manager = ModelLifecycleManager(config)
        manager.start_services()
        
        models = manager.list_models()
        
        if len(models) < 2:
            print("âŒ è‡³å°‘éœ€è¦2ä¸ªæ¨¡å‹æ‰èƒ½è¿›è¡Œå¯¹æ¯”")
            return
        
        print("\nğŸ”„ æ¨¡å‹å¯¹æ¯”åˆ†æ")
        print("é€‰æ‹©å¯¹æ¯”æ–¹å¼:")
        print("1. å¯¹æ¯”æ€§èƒ½æœ€å¥½çš„æ¨¡å‹")
        print("2. æ‰‹åŠ¨é€‰æ‹©æ¨¡å‹å¯¹æ¯”")
        print("0. è¿”å›ä¸»èœå•")
        
        choice = input("è¯·é€‰æ‹© (è¾“å…¥æ•°å­—): ").strip()
        
        if choice == '0':
            return
        elif choice == '1':
            # æŒ‰å‡†ç¡®ç‡æ’åº
            def get_accuracy(model):
                performance = model.get('performance', {})
                accuracy = performance.get('accuracy', 0)
                return accuracy if isinstance(accuracy, (int, float)) else 0
            
            sorted_models = sorted(models, key=get_accuracy, reverse=True)
            top_models = sorted_models[:min(5, len(sorted_models))]
            
            print(f"\nğŸ“Š å¯¹æ¯”æ€§èƒ½æœ€å¥½çš„ {len(top_models)} ä¸ªæ¨¡å‹:")
            
            model_ids = [model['id'] for model in top_models]
            
        elif choice == '2':
            print("\nğŸ“‹ å¯é€‰æ‹©çš„æ¨¡å‹:")
            for i, model in enumerate(models, 1):
                performance = model.get('performance', {})
                accuracy = performance.get('accuracy', 'N/A')
                print(f"{i}. {model['name']} (å‡†ç¡®ç‡: {accuracy})")
            
            selected = input("è¯·è¾“å…¥è¦å¯¹æ¯”çš„æ¨¡å‹åºå·ï¼Œç”¨ç©ºæ ¼åˆ†éš” (å¦‚: 1 2 3): ").strip().split()
            
            try:
                indices = [int(x) - 1 for x in selected]
                if any(i < 0 or i >= len(models) for i in indices):
                    print("âŒ æ— æ•ˆçš„æ¨¡å‹åºå·")
                    return
                
                if len(indices) < 2:
                    print("âŒ è‡³å°‘é€‰æ‹©2ä¸ªæ¨¡å‹")
                    return
                
                model_ids = [models[i]['id'] for i in indices]
                
            except ValueError:
                print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯")
                return
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            return
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        print("\nğŸ“Š ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
        report_path = manager.generate_comparison_report(
            model_ids=model_ids,
            output_format='html'
        )
        
        print(f"âœ… å¯¹æ¯”æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
        
        # æ˜¾ç¤ºç®€è¦å¯¹æ¯”
        print("\nğŸ“ˆ ç®€è¦å¯¹æ¯”:")
        print("-" * 60)
        print(f"{'æ¨¡å‹åç§°':<20} {'å‡†ç¡®ç‡':<10} {'F1åˆ†æ•°':<10}")
        print("-" * 60)
        
        for model_id in model_ids:
            model = manager.get_model(model_id)
            if model:
                performance = model.get('performance', {})
                accuracy = performance.get('accuracy', 'N/A')
                f1_score = performance.get('f1_score', 'N/A')
                
                if isinstance(accuracy, float):
                    accuracy = f"{accuracy:.4f}"
                if isinstance(f1_score, float):
                    f1_score = f"{f1_score:.4f}"
                
                print(f"{model['name']:<20} {accuracy:<10} {f1_score:<10}")
        
        print("-" * 60)
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹å¯¹æ¯”å¤±è´¥: {e}")

def show_system_status():
    """æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€"""
    try:
        config = ConfigManager().get_default_config()
        manager = ModelLifecycleManager(config)
        manager.start_services()
        
        print("\nğŸ“Š ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ")
        print("=" * 50)
        
        # æ¨¡å‹ç»Ÿè®¡
        models = manager.list_models()
        print(f"ğŸ“¦ æ¨¡å‹æ€»æ•°: {len(models)}")
        
        if models:
            # æŒ‰å‡†ç¡®ç‡æ’åº
            def get_accuracy(model):
                performance = model.get('performance', {})
                accuracy = performance.get('accuracy', 0)
                return accuracy if isinstance(accuracy, (int, float)) else 0
            
            sorted_models = sorted(models, key=get_accuracy, reverse=True)
            
            print(f"\nğŸ† æ€§èƒ½æ’è¡Œæ¦œ:")
            for i, model in enumerate(sorted_models[:5], 1):
                accuracy = get_accuracy(model)
                print(f"{i}. {model['name']}: {accuracy:.4f}")
        
        # å®éªŒç»Ÿè®¡
        experiments = manager.list_experiments()
        print(f"\nğŸ§ª å®éªŒæ€»æ•°: {len(experiments)}")
        
        # æœ€è¿‘çš„å®éªŒ
        if experiments:
            recent_experiments = sorted(experiments, key=lambda x: x.get('created_at', ''), reverse=True)[:3]
            print(f"\nğŸ“… æœ€è¿‘å®éªŒ:")
            for exp in recent_experiments:
                status = exp.get('status', 'N/A')
                name = exp.get('name', 'N/A')
                print(f"  - {name} ({status})")
        
        # å­˜å‚¨ä¿¡æ¯
        print(f"\nğŸ’¾ å­˜å‚¨ä¿¡æ¯:")
        for dir_name in ['models', 'experiments', 'reports', 'logs']:
            if os.path.exists(dir_name):
                size = sum(os.path.getsize(os.path.join(dir_name, f)) 
                          for f in os.listdir(dir_name) 
                          if os.path.isfile(os.path.join(dir_name, f)))
                size_mb = size / (1024 * 1024)
                print(f"  {dir_name}: {size_mb:.2f} MB")
        
        print("=" * 50)
        
    except Exception as e:
        print(f"âŒ è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")

def batch_train():
    """æ‰¹é‡è®­ç»ƒæ¨¡å‹"""
    print("\nğŸš€ æ‰¹é‡è®­ç»ƒæ¨¡å‹")
    print("è¿™å°†è®­ç»ƒæ‰€æœ‰å¯ç”¨çš„æ¨¡å‹ï¼Œå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ã€‚")
    
    confirm = input("ç¡®è®¤å¼€å§‹æ‰¹é‡è®­ç»ƒï¼Ÿ(y/N): ").strip().lower()
    if confirm != 'y':
        print("âŒ å–æ¶ˆæ‰¹é‡è®­ç»ƒ")
        return
    
    models_to_train = ['efficientnet_b0', 'resnet18_improved', 'airbubble_hybrid_net']
    
    data_path = input("æ•°æ®é›†è·¯å¾„ (å›è½¦ä½¿ç”¨é»˜è®¤ 'bioast_dataset'): ").strip()
    if not data_path:
        data_path = 'bioast_dataset'
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        return
    
    print(f"\nå¼€å§‹æ‰¹é‡è®­ç»ƒ {len(models_to_train)} ä¸ªæ¨¡å‹...")
    
    results = []
    for i, model_name in enumerate(models_to_train, 1):
        print(f"\n{'='*60}")
        print(f"è®­ç»ƒè¿›åº¦: {i}/{len(models_to_train)} - {model_name}")
        print(f"{'='*60}")
        
        success = train_single_model(model_name, data_path)
        results.append((model_name, success))
    
    # æ˜¾ç¤ºæ‰¹é‡è®­ç»ƒç»“æœ
    print(f"\n{'='*60}")
    print("æ‰¹é‡è®­ç»ƒå®Œæˆ")
    print(f"{'='*60}")
    
    for model_name, success in results:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"{model_name}: {status}")
    
    successful_count = sum(1 for _, success in results if success)
    print(f"\næ€»è®¡: {successful_count}/{len(results)} ä¸ªæ¨¡å‹è®­ç»ƒæˆåŠŸ")

def check_dataset():
    """æ£€æŸ¥æ•°æ®é›†"""
    print("\nğŸ” æ•°æ®é›†æ£€æŸ¥")
    
    data_path = input("æ•°æ®é›†è·¯å¾„ (å›è½¦ä½¿ç”¨é»˜è®¤ 'bioast_dataset'): ").strip()
    if not data_path:
        data_path = 'bioast_dataset'
    
    if not os.path.exists(data_path):
        print(f"âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {data_path}")
        return
    
    print(f"ğŸ“ æ£€æŸ¥æ•°æ®é›†: {data_path}")
    
    # æ£€æŸ¥ç›®å½•ç»“æ„
    required_dirs = ['train', 'val', 'test']
    for split in required_dirs:
        split_path = os.path.join(data_path, split)
        if os.path.exists(split_path):
            print(f"âœ… æ‰¾åˆ° {split} ç›®å½•")
            
            # æ£€æŸ¥ç±»åˆ«ç›®å½•
            classes = [d for d in os.listdir(split_path) 
                      if os.path.isdir(os.path.join(split_path, d))]
            
            if classes:
                print(f"  ç±»åˆ«: {', '.join(classes)}")
                
                # ç»Ÿè®¡æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
                for class_name in classes:
                    class_path = os.path.join(split_path, class_name)
                    files = [f for f in os.listdir(class_path) 
                            if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]
                    print(f"    {class_name}: {len(files)} ä¸ªæ ·æœ¬")
            else:
                print(f"  âš ï¸ {split} ç›®å½•ä¸ºç©º")
        else:
            print(f"âŒ ç¼ºå°‘ {split} ç›®å½•")
    
    print("\næ•°æ®é›†æ£€æŸ¥å®Œæˆ")

def generate_report():
    """ç”Ÿæˆç³»ç»ŸæŠ¥å‘Š"""
    try:
        config = ConfigManager().get_default_config()
        manager = ModelLifecycleManager(config)
        manager.start_services()
        
        print("\nğŸ“Š ç”Ÿæˆç³»ç»ŸæŠ¥å‘Š")
        print("é€‰æ‹©æŠ¥å‘Šç±»å‹:")
        print("1. ç³»ç»Ÿæ¦‚è§ˆæŠ¥å‘Š")
        print("2. æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š")
        print("3. å®éªŒè¯¦ç»†æŠ¥å‘Š")
        print("0. è¿”å›ä¸»èœå•")
        
        choice = input("è¯·é€‰æ‹© (è¾“å…¥æ•°å­—): ").strip()
        
        if choice == '0':
            return
        elif choice == '1':
            print("ç”Ÿæˆç³»ç»Ÿæ¦‚è§ˆæŠ¥å‘Š...")
            # è¿™é‡Œå¯ä»¥è°ƒç”¨ç³»ç»ŸæŠ¥å‘Šç”ŸæˆåŠŸèƒ½
            print("âœ… ç³»ç»Ÿæ¦‚è§ˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        elif choice == '2':
            models = manager.list_models()
            if len(models) < 2:
                print("âŒ è‡³å°‘éœ€è¦2ä¸ªæ¨¡å‹æ‰èƒ½ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š")
                return
            
            model_ids = [model['id'] for model in models]
            report_path = manager.generate_comparison_report(
                model_ids=model_ids,
                output_format='html'
            )
            print(f"âœ… æ¨¡å‹å¯¹æ¯”æŠ¥å‘Š: {report_path}")
        elif choice == '3':
            experiments = manager.list_experiments()
            if not experiments:
                print("âŒ æ²¡æœ‰å¯ç”¨çš„å®éªŒ")
                return
            
            print("\nå¯ç”¨å®éªŒ:")
            for i, exp in enumerate(experiments, 1):
                print(f"{i}. {exp.get('name', 'N/A')} ({exp.get('status', 'N/A')})")
            
            try:
                exp_index = int(input("é€‰æ‹©å®éªŒåºå·: ")) - 1
                if 0 <= exp_index < len(experiments):
                    experiment_id = experiments[exp_index]['id']
                    report_path = manager.generate_experiment_report(
                        experiment_id=experiment_id,
                        output_format='html'
                    )
                    print(f"âœ… å®éªŒæŠ¥å‘Š: {report_path}")
                else:
                    print("âŒ æ— æ•ˆçš„å®éªŒåºå·")
            except ValueError:
                print("âŒ è¾“å…¥æ ¼å¼é”™è¯¯")
        else:
            print("âŒ æ— æ•ˆé€‰æ‹©")
            
    except Exception as e:
        print(f"âŒ ç”ŸæˆæŠ¥å‘Šå¤±è´¥: {e}")

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("\nğŸ“š BioAstæ¨¡å‹ç®¡ç†ç³»ç»Ÿ - å¸®åŠ©æ–‡æ¡£")
    print("=" * 60)
    
    print("\nğŸ¯ ä¸»è¦åŠŸèƒ½:")
    print("1. å•æ¨¡å‹è®­ç»ƒ - è®­ç»ƒæŒ‡å®šçš„å•ä¸ªæ¨¡å‹")
    print("2. æ‰¹é‡è®­ç»ƒ - ä¸€æ¬¡æ€§è®­ç»ƒå¤šä¸ªæ¨¡å‹")
    print("3. æ¨¡å‹å¯¹æ¯” - æ¯”è¾ƒä¸åŒæ¨¡å‹çš„æ€§èƒ½")
    print("4. ç»“æœåˆ†æ - æŸ¥çœ‹è®­ç»ƒç»“æœå’Œæ€§èƒ½æŒ‡æ ‡")
    print("5. æŠ¥å‘Šç”Ÿæˆ - ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š")
    
    print("\nğŸ“‹ æ”¯æŒçš„æ¨¡å‹:")
    models = get_available_models()
    for key, model in models.items():
        print(f"  - {model['display_name']}: {model['description']}")
    
    print("\nğŸ“ æ–‡ä»¶ç»“æ„:")
    print("  bioast_dataset/     # æ•°æ®é›†ç›®å½•")
    print("  â”œâ”€â”€ train/          # è®­ç»ƒé›†")
    print("  â”œâ”€â”€ val/            # éªŒè¯é›†")
    print("  â””â”€â”€ test/           # æµ‹è¯•é›†")
    print("  models/             # æ¨¡å‹æ–‡ä»¶")
    print("  experiments/        # å®éªŒç»“æœ")
    print("  reports/            # åˆ†ææŠ¥å‘Š")
    print("  logs/               # æ—¥å¿—æ–‡ä»¶")
    
    print("\nğŸ”§ å‘½ä»¤è¡Œä½¿ç”¨:")
    print("  python quick_start.py                    # äº¤äº’å¼èœå•")
    print("  python quick_start.py train <model>      # è®­ç»ƒæŒ‡å®šæ¨¡å‹")
    print("  python quick_start.py list               # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹")
    print("  python quick_start.py compare            # å¯¹æ¯”æ¨¡å‹")
    print("  python quick_start.py status             # æŸ¥çœ‹ç³»ç»ŸçŠ¶æ€")
    
    print("\nğŸ“– æ›´å¤šæ–‡æ¡£:")
    print("  - README.md: å®Œæ•´ç³»ç»Ÿæ–‡æ¡£")
    print("  - MANUAL_OPERATION_GUIDE.md: æ‰‹åŠ¨æ“ä½œæŒ‡å—")
    print("  - config_template.yaml: é…ç½®æ–‡ä»¶æ¨¡æ¿")
    
    print("=" * 60)

def main():
    """ä¸»å‡½æ•°"""
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='BioAstæ¨¡å‹ç®¡ç†ç³»ç»Ÿ - å¿«é€Ÿå¼€å§‹')
    parser.add_argument('command', nargs='?', choices=['train', 'list', 'compare', 'status', 'help'], 
                       help='è¦æ‰§è¡Œçš„å‘½ä»¤')
    parser.add_argument('model', nargs='?', help='æ¨¡å‹åç§° (ç”¨äºtrainå‘½ä»¤)')
    parser.add_argument('--data', help='æ•°æ®é›†è·¯å¾„')
    
    args = parser.parse_args()
    
    # å¦‚æœæœ‰å‘½ä»¤è¡Œå‚æ•°ï¼Œç›´æ¥æ‰§è¡Œ
    if args.command:
        if args.command == 'train':
            if not args.model:
                print("âŒ è¯·æŒ‡å®šè¦è®­ç»ƒçš„æ¨¡å‹")
                print("å¯ç”¨æ¨¡å‹:", list(get_available_models().values()))
                return
            
            print_banner()
            if check_environment():
                success = train_single_model(args.model, args.data)
                if success:
                    print("\nâœ… è®­ç»ƒå®Œæˆ")
                else:
                    print("\nâŒ è®­ç»ƒå¤±è´¥")
        
        elif args.command == 'list':
            print_banner()
            list_models()
        
        elif args.command == 'compare':
            print_banner()
            compare_models_interactive()
        
        elif args.command == 'status':
            print_banner()
            show_system_status()
        
        elif args.command == 'help':
            show_help()
        
        return
    
    # äº¤äº’å¼èœå•
    print_banner()
    
    if not check_environment():
        print("âŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        return
    
    while True:
        try:
            show_main_menu()
            choice = input("è¯·é€‰æ‹©æ“ä½œ (è¾“å…¥æ•°å­—): ").strip()
            
            if choice == '0':
                print("\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ BioAstæ¨¡å‹ç®¡ç†ç³»ç»Ÿï¼")
                break
            elif choice == '1':
                train_model_interactive()
            elif choice == '2':
                list_models()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == '3':
                compare_models_interactive()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == '4':
                show_system_status()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == '5':
                batch_train()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == '6':
                check_dataset()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == '7':
                generate_report()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            elif choice == '8':
                show_help()
                input("\næŒ‰å›è½¦é”®ç»§ç»­...")
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¾“å…¥")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ BioAstæ¨¡å‹ç®¡ç†ç³»ç»Ÿï¼")
            break
        except Exception as e:
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
            input("æŒ‰å›è½¦é”®ç»§ç»­...")

if __name__ == "__main__":
    main()