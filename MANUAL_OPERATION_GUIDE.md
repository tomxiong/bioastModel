# BioAstæ¨¡å‹ç®¡ç†ç³»ç»Ÿ - æ‰‹åŠ¨æ“ä½œæŒ‡å—

æœ¬æŒ‡å—ä¸“ä¸ºéœ€è¦æ‰‹åŠ¨è¿›è¡Œå•ä¸ªæ¨¡å‹è®­ç»ƒã€ç»“æœåˆ†æå’Œå¯¹æ¯”åˆ†æçš„ç ”ç©¶äººå‘˜è®¾è®¡ã€‚

## ğŸ“‹ ç›®å½•

1. [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
2. [å•ä¸ªæ¨¡å‹è®­ç»ƒ](#å•ä¸ªæ¨¡å‹è®­ç»ƒ)
3. [ç»“æœåˆ†æ](#ç»“æœåˆ†æ)
4. [æ¨¡å‹å¯¹æ¯”åˆ†æ](#æ¨¡å‹å¯¹æ¯”åˆ†æ)
5. [æ•°æ®é›†æ›´æ–°æµç¨‹](#æ•°æ®é›†æ›´æ–°æµç¨‹)
6. [æŠ¥å‘Šè§„èŒƒ](#æŠ¥å‘Šè§„èŒƒ)
7. [æ–‡ä»¶ç»„ç»‡è§„èŒƒ](#æ–‡ä»¶ç»„ç»‡è§„èŒƒ)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡

```bash
# 1. æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
cd d:\ws1\bioastModel
venv\Scripts\activate

# 2. å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œï¼‰
pip install -r requirements.txt

# 3. éªŒè¯ç¯å¢ƒ
python -c "import torch; print('PyTorchç‰ˆæœ¬:', torch.__version__)"
```

### é¡¹ç›®ç»“æ„ç†è§£

```
bioastModel/
â”œâ”€â”€ models/                 # æ¨¡å‹å®šä¹‰æ–‡ä»¶
â”œâ”€â”€ scripts/               # è®­ç»ƒå’Œè¯„ä¼°è„šæœ¬
â”œâ”€â”€ experiments/           # å®éªŒç»“æœå­˜å‚¨
â”œâ”€â”€ reports/              # åˆ†ææŠ¥å‘Š
â”œâ”€â”€ data/                 # æ•°æ®é›†
â””â”€â”€ configs/              # é…ç½®æ–‡ä»¶
```

## ğŸ¯ å•ä¸ªæ¨¡å‹è®­ç»ƒ

### æ–¹æ³•1: ä½¿ç”¨ç°æœ‰è®­ç»ƒè„šæœ¬

```bash
# è®­ç»ƒç‰¹å®šæ¨¡å‹
python scripts/train_model.py --model efficientnet_b0
python scripts/train_model.py --model resnet18_improved
python scripts/train_model.py --model airbubble_hybrid_net
```

### æ–¹æ³•2: ä½¿ç”¨ç»Ÿä¸€è®­ç»ƒæ¥å£

```bash
# ä½¿ç”¨main.pyè¿›è¡Œå•æ¨¡å‹è®­ç»ƒ
python main.py --mode train --model efficientnet_b0
```

### æ–¹æ³•3: ä½¿ç”¨é›†æˆç®¡ç†å™¨ï¼ˆæ¨èï¼‰

åˆ›å»ºè®­ç»ƒè„šæœ¬ `train_single.py`ï¼š

```python
from utils.integration import ModelLifecycleManager
from utils.config import ConfigManager
import sys

def train_single_model(model_name, data_path=None):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    
    # åˆå§‹åŒ–ç®¡ç†å™¨
    config = ConfigManager().get_default_config()
    manager = ModelLifecycleManager(config)
    manager.start_services()
    
    # æ¨¡å‹é…ç½®
    model_configs = {
        'efficientnet_b0': {
            'name': 'EfficientNet-B0',
            'description': 'è½»é‡çº§é«˜æ•ˆæ¨¡å‹',
            'model_type': 'classification',
            'algorithm': 'efficientnet_b0',
            'data_config': {
                'data_path': data_path or 'bioast_dataset',
                'image_size': (70, 70),
                'batch_size': 32,
                'test_size': 0.2
            },
            'training_config': {
                'epochs': 50,
                'learning_rate': 0.001,
                'optimizer': 'adam'
            }
        },
        'resnet18_improved': {
            'name': 'ResNet18-Improved',
            'description': 'æ”¹è¿›ç‰ˆResNet18',
            'model_type': 'classification',
            'algorithm': 'resnet18_improved',
            'data_config': {
                'data_path': data_path or 'bioast_dataset',
                'image_size': (70, 70),
                'batch_size': 32,
                'test_size': 0.2
            },
            'training_config': {
                'epochs': 50,
                'learning_rate': 0.001,
                'optimizer': 'adam'
            }
        },
        'airbubble_hybrid_net': {
            'name': 'AirBubble-HybridNet',
            'description': 'æ··åˆæ¶æ„èŒè½æ£€æµ‹æ¨¡å‹',
            'model_type': 'classification',
            'algorithm': 'airbubble_hybrid_net',
            'data_config': {
                'data_path': data_path or 'bioast_dataset',
                'image_size': (70, 70),
                'batch_size': 32,
                'test_size': 0.2
            },
            'training_config': {
                'epochs': 50,
                'learning_rate': 0.001,
                'optimizer': 'adam'
            }
        }
    }
    
    if model_name not in model_configs:
        print(f"é”™è¯¯: ä¸æ”¯æŒçš„æ¨¡å‹ {model_name}")
        print(f"æ”¯æŒçš„æ¨¡å‹: {list(model_configs.keys())}")
        return None
    
    model_config = model_configs[model_name]
    
    print(f"å¼€å§‹è®­ç»ƒæ¨¡å‹: {model_config['name']}")
    
    # åˆ›å»ºè®­ç»ƒå·¥ä½œæµ
    workflow_id = manager.create_training_workflow(
        model_config=model_config,
        data_config=model_config['data_config'],
        training_config=model_config['training_config']
    )
    
    print(f"å·¥ä½œæµID: {workflow_id}")
    
    # æ‰§è¡Œè®­ç»ƒ
    success = manager.execute_workflow(workflow_id)
    
    if success:
        print("âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸï¼")
        
        # è·å–è®­ç»ƒç»“æœ
        workflow_status = manager.get_workflow_status(workflow_id)
        experiment_id = workflow_status.get('experiment_id')
        
        if experiment_id:
            # ç”Ÿæˆå®éªŒæŠ¥å‘Š
            report_path = manager.generate_experiment_report(
                experiment_id=experiment_id,
                output_format='html'
            )
            print(f"ğŸ“Š å®éªŒæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
            
            # è·å–æ¨¡å‹ä¿¡æ¯
            models = manager.list_models()
            latest_model = models[-1] if models else None
            
            if latest_model:
                print(f"ğŸ¯ æ¨¡å‹ID: {latest_model['id']}")
                print(f"ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡: {latest_model.get('performance', {})}")
                
                return {
                    'model_id': latest_model['id'],
                    'experiment_id': experiment_id,
                    'workflow_id': workflow_id,
                    'report_path': report_path,
                    'performance': latest_model.get('performance', {})
                }
    else:
        print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
        return None

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python train_single.py <model_name> [data_path]")
        print("æ”¯æŒçš„æ¨¡å‹: efficientnet_b0, resnet18_improved, airbubble_hybrid_net")
        sys.exit(1)
    
    model_name = sys.argv[1]
    data_path = sys.argv[2] if len(sys.argv) > 2 else None
    
    result = train_single_model(model_name, data_path)
    if result:
        print("\n=== è®­ç»ƒå®Œæˆ ===")
        print(f"æ¨¡å‹ID: {result['model_id']}")
        print(f"å®éªŒID: {result['experiment_id']}")
        print(f"æŠ¥å‘Šè·¯å¾„: {result['report_path']}")
```

ä½¿ç”¨æ–¹æ³•ï¼š
```bash
# è®­ç»ƒEfficientNet-B0
python train_single.py efficientnet_b0

# è®­ç»ƒResNet18-Improved
python train_single.py resnet18_improved

# ä½¿ç”¨è‡ªå®šä¹‰æ•°æ®è·¯å¾„
python train_single.py airbubble_hybrid_net /path/to/your/dataset
```

## ğŸ“Š ç»“æœåˆ†æ

### å•æ¨¡å‹åˆ†æ

åˆ›å»ºåˆ†æè„šæœ¬ `analyze_single.py`ï¼š

```python
from utils.integration import ModelLifecycleManager
from utils.config import ConfigManager
import sys

def analyze_model(model_id):
    """åˆ†æå•ä¸ªæ¨¡å‹"""
    
    config = ConfigManager().get_default_config()
    manager = ModelLifecycleManager(config)
    manager.start_services()
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    model = manager.get_model(model_id)
    if not model:
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹ {model_id}")
        return
    
    print(f"=== æ¨¡å‹åˆ†æ: {model['name']} ===")
    print(f"æ¨¡å‹ID: {model['id']}")
    print(f"åˆ›å»ºæ—¶é—´: {model.get('created_at', 'N/A')}")
    print(f"æ¨¡å‹ç±»å‹: {model.get('model_type', 'N/A')}")
    print(f"ç®—æ³•: {model.get('algorithm', 'N/A')}")
    
    # æ€§èƒ½æŒ‡æ ‡
    performance = model.get('performance', {})
    if performance:
        print("\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        for metric, value in performance.items():
            print(f"  {metric}: {value}")
    
    # è·å–ç›¸å…³å®éªŒ
    experiments = manager.list_experiments()
    model_experiments = [exp for exp in experiments if exp.get('model_id') == model_id]
    
    if model_experiments:
        print(f"\nğŸ§ª ç›¸å…³å®éªŒ ({len(model_experiments)}ä¸ª):")
        for exp in model_experiments:
            print(f"  - {exp['id']}: {exp.get('name', 'N/A')} (çŠ¶æ€: {exp.get('status', 'N/A')})")
    
    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    if model_experiments:
        latest_exp = model_experiments[-1]
        report_path = manager.generate_experiment_report(
            experiment_id=latest_exp['id'],
            output_format='html'
        )
        print(f"\nğŸ“Š è¯¦ç»†æŠ¥å‘Š: {report_path}")
    
    # å¯è§†åŒ–
    if model_experiments:
        latest_exp = model_experiments[-1]
        try:
            # ç”Ÿæˆè®­ç»ƒæ›²çº¿
            curve_path = manager.visualize_training_curves(
                experiment_id=latest_exp['id']
            )
            print(f"ğŸ“ˆ è®­ç»ƒæ›²çº¿: {curve_path}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•ç”Ÿæˆè®­ç»ƒæ›²çº¿: {e}")

def list_all_models():
    """åˆ—å‡ºæ‰€æœ‰æ¨¡å‹"""
    
    config = ConfigManager().get_default_config()
    manager = ModelLifecycleManager(config)
    manager.start_services()
    
    models = manager.list_models()
    
    if not models:
        print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹")
        return
    
    print(f"=== æ‰€æœ‰æ¨¡å‹ ({len(models)}ä¸ª) ===")
    for i, model in enumerate(models, 1):
        performance = model.get('performance', {})
        accuracy = performance.get('accuracy', 'N/A')
        print(f"{i}. {model['name']} (ID: {model['id']})")
        print(f"   å‡†ç¡®ç‡: {accuracy}")
        print(f"   åˆ›å»ºæ—¶é—´: {model.get('created_at', 'N/A')}")
        print()

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python analyze_single.py list                    # åˆ—å‡ºæ‰€æœ‰æ¨¡å‹")
        print("  python analyze_single.py <model_id>             # åˆ†æç‰¹å®šæ¨¡å‹")
        sys.exit(1)
    
    if sys.argv[1] == 'list':
        list_all_models()
    else:
        model_id = sys.argv[1]
        analyze_model(model_id)
```

ä½¿ç”¨æ–¹æ³•ï¼š
```bash
# åˆ—å‡ºæ‰€æœ‰æ¨¡å‹
python analyze_single.py list

# åˆ†æç‰¹å®šæ¨¡å‹
python analyze_single.py model_12345
```

## ğŸ”„ æ¨¡å‹å¯¹æ¯”åˆ†æ

åˆ›å»ºå¯¹æ¯”è„šæœ¬ `compare_models.py`ï¼š

```python
from utils.integration import ModelLifecycleManager
from utils.config import ConfigManager
import sys

def compare_models(model_ids):
    """å¯¹æ¯”å¤šä¸ªæ¨¡å‹"""
    
    config = ConfigManager().get_default_config()
    manager = ModelLifecycleManager(config)
    manager.start_services()
    
    print(f"=== æ¨¡å‹å¯¹æ¯”åˆ†æ ({len(model_ids)}ä¸ªæ¨¡å‹) ===")
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    models = []
    for model_id in model_ids:
        model = manager.get_model(model_id)
        if model:
            models.append(model)
        else:
            print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°æ¨¡å‹ {model_id}")
    
    if len(models) < 2:
        print("é”™è¯¯: è‡³å°‘éœ€è¦2ä¸ªæœ‰æ•ˆæ¨¡å‹è¿›è¡Œå¯¹æ¯”")
        return
    
    # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯å¯¹æ¯”
    print("\nğŸ“‹ åŸºæœ¬ä¿¡æ¯å¯¹æ¯”:")
    print(f"{'æ¨¡å‹åç§°':<20} {'æ¨¡å‹ID':<15} {'ç®—æ³•':<20} {'å‡†ç¡®ç‡':<10}")
    print("-" * 70)
    
    for model in models:
        performance = model.get('performance', {})
        accuracy = performance.get('accuracy', 'N/A')
        print(f"{model['name']:<20} {model['id']:<15} {model.get('algorithm', 'N/A'):<20} {accuracy:<10}")
    
    # æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”
    print("\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡è¯¦ç»†å¯¹æ¯”:")
    all_metrics = set()
    for model in models:
        performance = model.get('performance', {})
        all_metrics.update(performance.keys())
    
    if all_metrics:
        for metric in sorted(all_metrics):
            print(f"\n{metric}:")
            for model in models:
                performance = model.get('performance', {})
                value = performance.get(metric, 'N/A')
                print(f"  {model['name']}: {value}")
    
    # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
    try:
        report_path = manager.generate_comparison_report(
            model_ids=[model['id'] for model in models],
            output_format='html'
        )
        print(f"\nğŸ“Š è¯¦ç»†å¯¹æ¯”æŠ¥å‘Š: {report_path}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š: {e}")
    
    # å¯è§†åŒ–å¯¹æ¯”
    try:
        dashboard_url = manager.create_interactive_dashboard(
            model_ids=[model['id'] for model in models]
        )
        print(f"ğŸŒ äº¤äº’å¼ä»ªè¡¨æ¿: {dashboard_url}")
    except Exception as e:
        print(f"âš ï¸ æ— æ³•åˆ›å»ºä»ªè¡¨æ¿: {e}")
    
    # æ¨èæœ€ä½³æ¨¡å‹
    best_model = None
    best_accuracy = 0
    
    for model in models:
        performance = model.get('performance', {})
        accuracy = performance.get('accuracy', 0)
        if isinstance(accuracy, (int, float)) and accuracy > best_accuracy:
            best_accuracy = accuracy
            best_model = model
    
    if best_model:
        print(f"\nğŸ† æ¨èæ¨¡å‹: {best_model['name']} (å‡†ç¡®ç‡: {best_accuracy})")

def compare_top_models(top_n=5):
    """å¯¹æ¯”æ€§èƒ½æœ€å¥½çš„Nä¸ªæ¨¡å‹"""
    
    config = ConfigManager().get_default_config()
    manager = ModelLifecycleManager(config)
    manager.start_services()
    
    models = manager.list_models()
    
    if not models:
        print("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹")
        return
    
    # æŒ‰å‡†ç¡®ç‡æ’åº
    def get_accuracy(model):
        performance = model.get('performance', {})
        accuracy = performance.get('accuracy', 0)
        return accuracy if isinstance(accuracy, (int, float)) else 0
    
    sorted_models = sorted(models, key=get_accuracy, reverse=True)
    top_models = sorted_models[:top_n]
    
    print(f"=== Top {len(top_models)} æ¨¡å‹å¯¹æ¯” ===")
    
    model_ids = [model['id'] for model in top_models]
    compare_models(model_ids)

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•:")
        print("  python compare_models.py top [N]                # å¯¹æ¯”æ€§èƒ½æœ€å¥½çš„Nä¸ªæ¨¡å‹(é»˜è®¤5ä¸ª)")
        print("  python compare_models.py <model_id1> <model_id2> [model_id3] ...  # å¯¹æ¯”æŒ‡å®šæ¨¡å‹")
        sys.exit(1)
    
    if sys.argv[1] == 'top':
        top_n = int(sys.argv[2]) if len(sys.argv) > 2 else 5
        compare_top_models(top_n)
    else:
        model_ids = sys.argv[1:]
        compare_models(model_ids)
```

ä½¿ç”¨æ–¹æ³•ï¼š
```bash
# å¯¹æ¯”æ€§èƒ½æœ€å¥½çš„5ä¸ªæ¨¡å‹
python compare_models.py top

# å¯¹æ¯”æ€§èƒ½æœ€å¥½çš„3ä¸ªæ¨¡å‹
python compare_models.py top 3

# å¯¹æ¯”æŒ‡å®šæ¨¡å‹
python compare_models.py model_123 model_456 model_789
```

## ğŸ”„ æ•°æ®é›†æ›´æ–°æµç¨‹

### 1. æ•°æ®é›†æ›´æ–°æ£€æµ‹

åˆ›å»º `check_dataset_updates.py`ï¼š

```python
import os
import hashlib
import json
from datetime import datetime

def calculate_dataset_hash(dataset_path):
    """è®¡ç®—æ•°æ®é›†å“ˆå¸Œå€¼"""
    hash_md5 = hashlib.md5()
    
    for root, dirs, files in os.walk(dataset_path):
        for file in sorted(files):
            if file.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):
                file_path = os.path.join(root, file)
                with open(file_path, 'rb') as f:
                    for chunk in iter(lambda: f.read(4096), b""):
                        hash_md5.update(chunk)
    
    return hash_md5.hexdigest()

def check_dataset_changes(dataset_path, hash_file='dataset_hash.json'):
    """æ£€æŸ¥æ•°æ®é›†æ˜¯å¦æœ‰å˜åŒ–"""
    
    current_hash = calculate_dataset_hash(dataset_path)
    
    # è¯»å–ä¹‹å‰çš„å“ˆå¸Œå€¼
    previous_hash = None
    if os.path.exists(hash_file):
        try:
            with open(hash_file, 'r') as f:
                data = json.load(f)
                previous_hash = data.get('hash')
        except:
            pass
    
    # ä¿å­˜å½“å‰å“ˆå¸Œå€¼
    with open(hash_file, 'w') as f:
        json.dump({
            'hash': current_hash,
            'timestamp': datetime.now().isoformat(),
            'dataset_path': dataset_path
        }, f, indent=2)
    
    if previous_hash is None:
        print("é¦–æ¬¡æ£€æŸ¥æ•°æ®é›†")
        return True
    elif previous_hash != current_hash:
        print("âš ï¸ æ£€æµ‹åˆ°æ•°æ®é›†å˜åŒ–ï¼Œéœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹")
        return True
    else:
        print("âœ… æ•°æ®é›†æ— å˜åŒ–")
        return False

if __name__ == "__main__":
    dataset_path = "bioast_dataset"  # ä¿®æ”¹ä¸ºä½ çš„æ•°æ®é›†è·¯å¾„
    
    if check_dataset_changes(dataset_path):
        print("\nå»ºè®®æ‰§è¡Œä»¥ä¸‹æ“ä½œ:")
        print("1. é‡æ–°è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
        print("2. æ›´æ–°æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
        print("3. ç”Ÿæˆæ–°çš„åˆ†ææŠ¥å‘Š")
        
        print("\nå¿«é€Ÿé‡è®­ç»ƒå‘½ä»¤:")
        models = ['efficientnet_b0', 'resnet18_improved', 'airbubble_hybrid_net']
        for model in models:
            print(f"python train_single.py {model}")
```

### 2. æ‰¹é‡é‡è®­ç»ƒè„šæœ¬

åˆ›å»º `retrain_all.py`ï¼š

```python
from utils.integration import ModelLifecycleManager
from utils.config import ConfigManager
import time

def retrain_all_models(data_path=None):
    """é‡æ–°è®­ç»ƒæ‰€æœ‰æ¨¡å‹"""
    
    models_to_train = [
        'efficientnet_b0',
        'resnet18_improved', 
        'airbubble_hybrid_net',
        'micro_vit',
        'convnext_tiny'
    ]
    
    results = []
    
    for model_name in models_to_train:
        print(f"\n{'='*50}")
        print(f"å¼€å§‹è®­ç»ƒ: {model_name}")
        print(f"{'='*50}")
        
        start_time = time.time()
        
        # è¿™é‡Œè°ƒç”¨ä¹‹å‰å®šä¹‰çš„train_single_modelå‡½æ•°
        from train_single import train_single_model
        result = train_single_model(model_name, data_path)
        
        end_time = time.time()
        training_time = end_time - start_time
        
        if result:
            result['training_time'] = training_time
            results.append(result)
            print(f"âœ… {model_name} è®­ç»ƒå®Œæˆ (è€—æ—¶: {training_time:.2f}ç§’)")
        else:
            print(f"âŒ {model_name} è®­ç»ƒå¤±è´¥")
    
    # ç”Ÿæˆæ±‡æ€»æŠ¥å‘Š
    print(f"\n{'='*50}")
    print("è®­ç»ƒæ±‡æ€»")
    print(f"{'='*50}")
    
    for result in results:
        performance = result.get('performance', {})
        accuracy = performance.get('accuracy', 'N/A')
        training_time = result.get('training_time', 0)
        print(f"æ¨¡å‹: {result['model_id']}")
        print(f"  å‡†ç¡®ç‡: {accuracy}")
        print(f"  è®­ç»ƒæ—¶é—´: {training_time:.2f}ç§’")
        print(f"  æŠ¥å‘Š: {result['report_path']}")
        print()
    
    # è‡ªåŠ¨ç”Ÿæˆå¯¹æ¯”åˆ†æ
    if len(results) >= 2:
        print("ç”Ÿæˆæ¨¡å‹å¯¹æ¯”åˆ†æ...")
        model_ids = [result['model_id'] for result in results]
        
        config = ConfigManager().get_default_config()
        manager = ModelLifecycleManager(config)
        manager.start_services()
        
        try:
            comparison_report = manager.generate_comparison_report(
                model_ids=model_ids,
                output_format='html'
            )
            print(f"ğŸ“Š å¯¹æ¯”æŠ¥å‘Š: {comparison_report}")
        except Exception as e:
            print(f"âš ï¸ æ— æ³•ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š: {e}")

if __name__ == "__main__":
    import sys
    data_path = sys.argv[1] if len(sys.argv) > 1 else None
    retrain_all_models(data_path)
```

## ğŸ“‹ æŠ¥å‘Šè§„èŒƒ

### æŠ¥å‘Šæ–‡ä»¶å‘½åè§„èŒƒ

```
reports/
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ exp_YYYYMMDD_HHMMSS_<model_name>.html
â”‚   â””â”€â”€ exp_YYYYMMDD_HHMMSS_<model_name>.json
â”œâ”€â”€ comparisons/
â”‚   â”œâ”€â”€ comparison_YYYYMMDD_HHMMSS.html
â”‚   â””â”€â”€ comparison_YYYYMMDD_HHMMSS.json
â””â”€â”€ summaries/
    â”œâ”€â”€ summary_YYYYMMDD.html
    â””â”€â”€ summary_YYYYMMDD.json
```

### æŠ¥å‘Šå†…å®¹è§„èŒƒ

æ¯ä¸ªå®éªŒæŠ¥å‘Šåº”åŒ…å«ï¼š

1. **åŸºæœ¬ä¿¡æ¯**
   - æ¨¡å‹åç§°å’ŒID
   - è®­ç»ƒæ—¶é—´
   - æ•°æ®é›†ä¿¡æ¯
   - è¶…å‚æ•°é…ç½®

2. **æ€§èƒ½æŒ‡æ ‡**
   - å‡†ç¡®ç‡ (Accuracy)
   - ç²¾ç¡®ç‡ (Precision)
   - å¬å›ç‡ (Recall)
   - F1åˆ†æ•° (F1-Score)
   - æ··æ·†çŸ©é˜µ

3. **è®­ç»ƒè¿‡ç¨‹**
   - è®­ç»ƒæ›²çº¿
   - æŸå¤±å‡½æ•°å˜åŒ–
   - éªŒè¯é›†æ€§èƒ½å˜åŒ–

4. **é”™è¯¯åˆ†æ**
   - é”™è¯¯æ ·æœ¬åˆ†æ
   - åˆ†ç±»é”™è¯¯ç»Ÿè®¡

## ğŸ“ æ–‡ä»¶ç»„ç»‡è§„èŒƒ

### å®éªŒæ–‡ä»¶ç»„ç»‡

```
experiments/
â”œâ”€â”€ YYYYMMDD_HHMMSS_<model_name>/
â”‚   â”œâ”€â”€ config.json              # è®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ model.pth               # è®­ç»ƒå¥½çš„æ¨¡å‹
â”‚   â”œâ”€â”€ training_log.txt        # è®­ç»ƒæ—¥å¿—
â”‚   â”œâ”€â”€ metrics.json            # æ€§èƒ½æŒ‡æ ‡
â”‚   â”œâ”€â”€ plots/                  # å›¾è¡¨æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ training_curve.png
â”‚   â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”‚   â””â”€â”€ roc_curve.png
â”‚   â””â”€â”€ artifacts/              # å…¶ä»–äº§ç‰©
â”‚       â”œâ”€â”€ predictions.csv
â”‚       â””â”€â”€ error_samples/
```

### é…ç½®æ–‡ä»¶æ¨¡æ¿

åˆ›å»º `config_template.json`ï¼š

```json
{
  "model": {
    "name": "æ¨¡å‹åç§°",
    "type": "classification",
    "algorithm": "ç®—æ³•åç§°",
    "version": "1.0.0"
  },
  "data": {
    "dataset_path": "æ•°æ®é›†è·¯å¾„",
    "image_size": [70, 70],
    "batch_size": 32,
    "train_split": 0.8,
    "val_split": 0.1,
    "test_split": 0.1
  },
  "training": {
    "epochs": 50,
    "learning_rate": 0.001,
    "optimizer": "adam",
    "loss_function": "cross_entropy",
    "early_stopping": {
      "patience": 10,
      "min_delta": 0.001
    }
  },
  "evaluation": {
    "metrics": ["accuracy", "precision", "recall", "f1_score"],
    "save_predictions": true,
    "save_error_analysis": true
  }
}
```

## ğŸ”§ å®ç”¨å·¥å…·è„šæœ¬

### å¿«é€ŸçŠ¶æ€æ£€æŸ¥

åˆ›å»º `quick_status.py`ï¼š

```python
from utils.integration import ModelLifecycleManager
from utils.config import ConfigManager

def quick_status():
    """å¿«é€ŸæŸ¥çœ‹ç³»ç»ŸçŠ¶æ€"""
    
    config = ConfigManager().get_default_config()
    manager = ModelLifecycleManager(config)
    manager.start_services()
    
    # æ¨¡å‹ç»Ÿè®¡
    models = manager.list_models()
    print(f"ğŸ“Š ç³»ç»ŸçŠ¶æ€æ¦‚è§ˆ")
    print(f"æ¨¡å‹æ€»æ•°: {len(models)}")
    
    if models:
        # æŒ‰å‡†ç¡®ç‡æ’åº
        def get_accuracy(model):
            performance = model.get('performance', {})
            accuracy = performance.get('accuracy', 0)
            return accuracy if isinstance(accuracy, (int, float)) else 0
        
        sorted_models = sorted(models, key=get_accuracy, reverse=True)
        
        print(f"\nğŸ† æ€§èƒ½æ’è¡Œæ¦œ (Top 5):")
        for i, model in enumerate(sorted_models[:5], 1):
            accuracy = get_accuracy(model)
            print(f"{i}. {model['name']}: {accuracy:.4f}")
    
    # å®éªŒç»Ÿè®¡
    experiments = manager.list_experiments()
    print(f"\nğŸ§ª å®éªŒæ€»æ•°: {len(experiments)}")
    
    # æœ€è¿‘çš„å®éªŒ
    if experiments:
        recent_experiments = sorted(experiments, key=lambda x: x.get('created_at', ''), reverse=True)[:3]
        print(f"\nğŸ“… æœ€è¿‘å®éªŒ:")
        for exp in recent_experiments:
            print(f"  - {exp.get('name', 'N/A')} ({exp.get('status', 'N/A')})")

if __name__ == "__main__":
    quick_status()
```

### æ¸…ç†å·¥å…·

åˆ›å»º `cleanup.py`ï¼š

```python
import os
import shutil
from datetime import datetime, timedelta

def cleanup_old_files(days=30):
    """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„æ–‡ä»¶"""
    
    cutoff_date = datetime.now() - timedelta(days=days)
    
    # æ¸…ç†ç›®å½•
    cleanup_dirs = [
        'experiments',
        'reports',
        'logs'
    ]
    
    for dir_name in cleanup_dirs:
        if not os.path.exists(dir_name):
            continue
            
        print(f"æ¸…ç†ç›®å½•: {dir_name}")
        
        for item in os.listdir(dir_name):
            item_path = os.path.join(dir_name, item)
            
            # è·å–æ–‡ä»¶/ç›®å½•çš„ä¿®æ”¹æ—¶é—´
            mtime = datetime.fromtimestamp(os.path.getmtime(item_path))
            
            if mtime < cutoff_date:
                if os.path.isdir(item_path):
                    shutil.rmtree(item_path)
                    print(f"  åˆ é™¤ç›®å½•: {item}")
                else:
                    os.remove(item_path)
                    print(f"  åˆ é™¤æ–‡ä»¶: {item}")

if __name__ == "__main__":
    import sys
    days = int(sys.argv[1]) if len(sys.argv) > 1 else 30
    print(f"æ¸…ç† {days} å¤©å‰çš„æ–‡ä»¶...")
    cleanup_old_files(days)
    print("æ¸…ç†å®Œæˆ")
```

## ğŸš€ å®Œæ•´å·¥ä½œæµç¤ºä¾‹

### æ–°æ•°æ®é›†è®­ç»ƒå®Œæ•´æµç¨‹

```bash
# 1. æ£€æŸ¥æ•°æ®é›†å˜åŒ–
python check_dataset_updates.py

# 2. å¦‚æœæœ‰å˜åŒ–ï¼Œé‡æ–°è®­ç»ƒæ‰€æœ‰æ¨¡å‹
python retrain_all.py

# 3. æŸ¥çœ‹è®­ç»ƒç»“æœ
python quick_status.py

# 4. å¯¹æ¯”æœ€å¥½çš„3ä¸ªæ¨¡å‹
python compare_models.py top 3

# 5. åˆ†æç‰¹å®šæ¨¡å‹
python analyze_single.py <model_id>
```

### å•æ¨¡å‹è°ƒä¼˜æµç¨‹

```bash
# 1. è®­ç»ƒåŸºç¡€æ¨¡å‹
python train_single.py efficientnet_b0

# 2. åˆ†æç»“æœ
python analyze_single.py <model_id>

# 3. è°ƒæ•´è¶…å‚æ•°åé‡æ–°è®­ç»ƒ
# (ä¿®æ”¹train_single.pyä¸­çš„é…ç½®)
python train_single.py efficientnet_b0

# 4. å¯¹æ¯”ä¸åŒç‰ˆæœ¬
python compare_models.py <model_id_v1> <model_id_v2>
```

## ğŸ“ æ³¨æ„äº‹é¡¹

1. **æ•°æ®å¤‡ä»½**: è®­ç»ƒå‰ç¡®ä¿æ•°æ®é›†å·²å¤‡ä»½
2. **èµ„æºç›‘æ§**: è®­ç»ƒæ—¶ç›‘æ§GPU/CPUä½¿ç”¨æƒ…å†µ
3. **æ—¥å¿—ä¿å­˜**: æ‰€æœ‰è®­ç»ƒè¿‡ç¨‹éƒ½ä¼šè‡ªåŠ¨è®°å½•æ—¥å¿—
4. **ç‰ˆæœ¬ç®¡ç†**: æ¯æ¬¡è®­ç»ƒéƒ½ä¼šåˆ›å»ºæ–°çš„æ¨¡å‹ç‰ˆæœ¬
5. **æŠ¥å‘Šå½’æ¡£**: å®šæœŸæ¸…ç†æ—§çš„æŠ¥å‘Šæ–‡ä»¶

## ğŸ”— ç›¸å…³æ–‡ä»¶

- `main.py`: ç³»ç»Ÿä¸»å…¥å£
- `utils/integration.py`: æ ¸å¿ƒç®¡ç†å™¨
- `utils/config.py`: é…ç½®ç®¡ç†
- `requirements.txt`: ä¾èµ–åŒ…åˆ—è¡¨
- `README.md`: ç³»ç»Ÿå®Œæ•´æ–‡æ¡£

---

**æç¤º**: è¿™ä¸ªæŒ‡å—ä¸“æ³¨äºæ‰‹åŠ¨æ“ä½œï¼Œå¦‚æœéœ€è¦æ›´å¤šè‡ªåŠ¨åŒ–åŠŸèƒ½ï¼Œå¯ä»¥å‚è€ƒå®Œæ•´çš„ç³»ç»Ÿæ–‡æ¡£ã€‚