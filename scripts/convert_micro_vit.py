"""
å°† Micro ViT æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼ã€‚

è¿™ä¸ªè„šæœ¬ä¸“é—¨ç”¨äºå¤„ç† Micro ViT æ¨¡å‹çš„æƒé‡åŠ è½½é—®é¢˜ï¼Œ
å› ä¸ºæƒé‡æ–‡ä»¶ä¸­çš„é”®åå¯èƒ½ä¸æ¨¡å‹ç±»ä¸­çš„é”®åä¸åŒ¹é…ã€‚
"""

import os
import sys
import torch
import logging
import argparse
import numpy as np
from pathlib import Path

# è®¾ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# å¯¼å…¥æ¨¡å‹
from models.micro_vit import MicroViT

def convert_model_to_onnx(model_path, output_dir="deployment/onnx_models"):
    """
    å°† Micro ViT æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼ã€‚
    
    Args:
        model_path: æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """
    logging.info(f"ğŸš€ å¼€å§‹è½¬æ¢æ¨¡å‹: micro_vit")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(output_dir, exist_ok=True)
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹
    model = MicroViT(num_classes=2)
    
    try:
        # åŠ è½½æƒé‡
        state_dict = torch.load(model_path, map_location="cpu")
        
        # å¤„ç†æƒé‡é”®åä¸åŒ¹é…çš„é—®é¢˜
        new_state_dict = {}
        for key, value in state_dict.items():
            if key.startswith("base_model."):
                new_key = key.replace("base_model.", "")
                new_state_dict[new_key] = value
            else:
                new_state_dict[key] = value
        
        # åŠ è½½å¤„ç†åçš„æƒé‡
        model.load_state_dict(new_state_dict, strict=False)
        logging.info(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹æƒé‡: {model_path}")
        
        # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        model.eval()
        
        # åˆ›å»ºç¤ºä¾‹è¾“å…¥
        dummy_input = torch.randn(1, 3, 70, 70)
        
        # å®šä¹‰è¾“å‡ºè·¯å¾„
        onnx_path = os.path.join(output_dir, "micro_vit.onnx")
        
        # è½¬æ¢ä¸º ONNX
        torch.onnx.export(
            model,
            dummy_input,
            onnx_path,
            export_params=True,
            opset_version=12,
            do_constant_folding=True,
            input_names=["input"],
            output_names=["output"],
            dynamic_axes={"input": {0: "batch_size"}, "output": {0: "batch_size"}},
        )
        
        # è·å–æ–‡ä»¶å¤§å°
        file_size = Path(onnx_path).stat().st_size / (1024 * 1024)  # MB
        logging.info(f"âœ… æˆåŠŸè½¬æ¢æ¨¡å‹ -> {onnx_path} ({file_size:.2f} MB)")
        
        # æµ‹è¯• ONNX æ¨¡å‹
        import onnxruntime as ort
        
        # åˆ›å»º ONNX è¿è¡Œæ—¶ä¼šè¯
        ort_session = ort.InferenceSession(onnx_path)
        
        # å‡†å¤‡è¾“å…¥
        ort_inputs = {ort_session.get_inputs()[0].name: dummy_input.numpy()}
        
        # è¿è¡Œæ¨ç†
        ort_outputs = ort_session.run(None, ort_inputs)
        
        # è¾“å‡ºå½¢çŠ¶å’ŒèŒƒå›´
        output_shape = ort_outputs[0].shape
        output_range = [float(np.min(ort_outputs[0])), float(np.max(ort_outputs[0]))]
        
        logging.info(f"âœ… ONNXæ¨¡å‹æµ‹è¯•æˆåŠŸ: {onnx_path}")
        logging.info(f"   è¾“å‡ºå½¢çŠ¶: {output_shape}")
        logging.info(f"   è¾“å‡ºèŒƒå›´: {output_range}")
        logging.info(f"âœ… æ¨¡å‹ micro_vit è½¬æ¢å¹¶æµ‹è¯•æˆåŠŸ!")
        
        logging.info(f"\nğŸ‰ æ¨¡å‹ micro_vit è½¬æ¢æˆåŠŸ!")
        logging.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        
        return True
    except Exception as e:
        logging.error(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        logging.error(f"\nâŒ æ¨¡å‹ micro_vit è½¬æ¢å¤±è´¥!")
        return False

def main():
    parser = argparse.ArgumentParser(description="å°† Micro ViT æ¨¡å‹è½¬æ¢ä¸º ONNX æ ¼å¼")
    parser.add_argument("--model_path", type=str, required=True, help="æ¨¡å‹æƒé‡æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_dir", type=str, default="deployment/onnx_models", help="è¾“å‡ºç›®å½•")
    
    args = parser.parse_args()
    
    convert_model_to_onnx(args.model_path, args.output_dir)

if __name__ == "__main__":
    main()