#!/usr/bin/env python3
"""
ç”Ÿæˆæœ€ç»ˆçš„å®Œæ•´æ€§èƒ½åˆ†ææŠ¥å‘Š
"""

import os
import json
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import numpy as np

def load_all_results():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹çš„æµ‹è¯•ç»“æœ"""
    experiments = [
        ('experiments/experiment_20250802_140818/efficientnet_b0', 'EfficientNet-B0'),
        ('experiments/experiment_20250802_164948/resnet18_improved', 'ResNet18-Improved'),
        ('experiments/experiment_20250802_231639/convnext_tiny', 'ConvNext-Tiny'),
        ('experiments/experiment_20250803_020217/vit_tiny', 'ViT-Tiny'),
        ('experiments/experiment_20250803_032628/coatnet', 'CoAtNet'),
        ('experiments/experiment_20250803_101438/mic_mobilenetv3', 'MIC_MobileNetV3'),
        ('experiments/experiment_20250803_102845/micro_vit', 'Micro-ViT'),
        ('experiments/experiment_20250803_115344/airbubble_hybrid_net', 'AirBubble_HybridNet')
    ]
    
    results = []
    for exp_path, model_name in experiments:
        result_file = os.path.join(exp_path, 'test_results.json')
        if os.path.exists(result_file):
            with open(result_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
                data['model_name'] = model_name
                data['experiment_path'] = exp_path
                results.append(data)
        else:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°ç»“æœæ–‡ä»¶ {result_file}")
    
    return results

def generate_performance_comparison():
    """ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨"""
    results = load_all_results()
    
    # åˆ›å»ºDataFrame
    df_data = []
    for result in results:
        df_data.append({
            'Model': result['model_name'],
            'Accuracy': result['accuracy'] * 100,
            'Precision': result['precision'] * 100,
            'Recall': result['recall'] * 100,
            'F1-Score': result['f1_score'] * 100,
            'AUC': result['auc'] * 100,
            'Sensitivity': result['sensitivity'] * 100,
            'Specificity': result['specificity'] * 100
        })
    
    df = pd.DataFrame(df_data)
    df = df.sort_values('Accuracy', ascending=False)
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
    
    # åˆ›å»ºæ€§èƒ½å¯¹æ¯”å›¾
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('æ¨¡å‹æ€§èƒ½å…¨é¢å¯¹æ¯”åˆ†æ', fontsize=16, fontweight='bold')
    
    # å‡†ç¡®ç‡å¯¹æ¯”
    ax1 = axes[0, 0]
    bars1 = ax1.bar(range(len(df)), df['Accuracy'], color='skyblue', alpha=0.8)
    ax1.set_title('å‡†ç¡®ç‡å¯¹æ¯”', fontweight='bold')
    ax1.set_ylabel('å‡†ç¡®ç‡ (%)')
    ax1.set_xticks(range(len(df)))
    ax1.set_xticklabels(df['Model'], rotation=45, ha='right')
    ax1.grid(axis='y', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars1):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{height:.2f}%', ha='center', va='bottom', fontweight='bold')
    
    # F1åˆ†æ•°å¯¹æ¯”
    ax2 = axes[0, 1]
    bars2 = ax2.bar(range(len(df)), df['F1-Score'], color='lightgreen', alpha=0.8)
    ax2.set_title('F1åˆ†æ•°å¯¹æ¯”', fontweight='bold')
    ax2.set_ylabel('F1åˆ†æ•° (%)')
    ax2.set_xticks(range(len(df)))
    ax2.set_xticklabels(df['Model'], rotation=45, ha='right')
    ax2.grid(axis='y', alpha=0.3)
    
    for i, bar in enumerate(bars2):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{height:.2f}%', ha='center', va='bottom', fontweight='bold')
    
    # AUCå¯¹æ¯”
    ax3 = axes[1, 0]
    bars3 = ax3.bar(range(len(df)), df['AUC'], color='orange', alpha=0.8)
    ax3.set_title('AUCå¯¹æ¯”', fontweight='bold')
    ax3.set_ylabel('AUC (%)')
    ax3.set_xticks(range(len(df)))
    ax3.set_xticklabels(df['Model'], rotation=45, ha='right')
    ax3.grid(axis='y', alpha=0.3)
    
    for i, bar in enumerate(bars3):
        height = bar.get_height()
        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                f'{height:.2f}%', ha='center', va='bottom', fontweight='bold')
    
    # æ•æ„Ÿæ€§vsç‰¹å¼‚æ€§æ•£ç‚¹å›¾
    ax4 = axes[1, 1]
    scatter = ax4.scatter(df['Sensitivity'], df['Specificity'], 
                         c=df['Accuracy'], cmap='viridis', s=100, alpha=0.8)
    ax4.set_title('æ•æ„Ÿæ€§ vs ç‰¹å¼‚æ€§', fontweight='bold')
    ax4.set_xlabel('æ•æ„Ÿæ€§ (%)')
    ax4.set_ylabel('ç‰¹å¼‚æ€§ (%)')
    ax4.grid(alpha=0.3)
    
    # æ·»åŠ æ¨¡å‹åç§°æ ‡ç­¾
    for i, model in enumerate(df['Model']):
        ax4.annotate(model, (df['Sensitivity'].iloc[i], df['Specificity'].iloc[i]),
                    xytext=(5, 5), textcoords='offset points', fontsize=8)
    
    # æ·»åŠ é¢œè‰²æ¡
    cbar = plt.colorbar(scatter, ax=ax4)
    cbar.set_label('å‡†ç¡®ç‡ (%)')
    
    plt.tight_layout()
    plt.savefig('reports/final_performance_comparison.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    return df

def generate_detailed_report():
    """ç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Š"""
    results = load_all_results()
    df = generate_performance_comparison()
    
    report = f"""# ç”Ÿç‰©æŠ—èŒç´ æ•æ„Ÿæ€§æµ‹è¯• - æ¨¡å‹æ€§èƒ½å®Œæ•´åˆ†ææŠ¥å‘Š

## æŠ¥å‘Šæ¦‚è¦
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æµ‹è¯•æ¨¡å‹æ•°é‡**: {len(results)}
- **æ•°æ®é›†**: 70Ã—70åƒç´ èŒè½æ£€æµ‹å›¾åƒ
- **ä»»åŠ¡**: äºŒåˆ†ç±»ï¼ˆé˜³æ€§/é˜´æ€§ï¼‰

## æ€§èƒ½æ’å

### æŒ‰å‡†ç¡®ç‡æ’åºï¼š
"""
    
    for i, (_, row) in enumerate(df.iterrows(), 1):
        report += f"{i}. **{row['Model']}**: {row['Accuracy']:.2f}%\n"
    
    report += f"""

## è¯¦ç»†æ€§èƒ½æŒ‡æ ‡

| æ¨¡å‹ | å‡†ç¡®ç‡ | ç²¾ç¡®ç‡ | å¬å›ç‡ | F1åˆ†æ•° | AUC | æ•æ„Ÿæ€§ | ç‰¹å¼‚æ€§ |
|------|--------|--------|--------|--------|-----|--------|--------|
"""
    
    for _, row in df.iterrows():
        report += f"| {row['Model']} | {row['Accuracy']:.2f}% | {row['Precision']:.2f}% | {row['Recall']:.2f}% | {row['F1-Score']:.2f}% | {row['AUC']:.2f}% | {row['Sensitivity']:.2f}% | {row['Specificity']:.2f}% |\n"
    
    report += f"""

## å…³é”®å‘ç°

### ğŸ† æœ€ä½³æ€§èƒ½æ¨¡å‹
- **ResNet18-Improved** ä»¥ **{df.iloc[0]['Accuracy']:.2f}%** çš„å‡†ç¡®ç‡ä½å±…ç¬¬ä¸€
- åœ¨æ‰€æœ‰æŒ‡æ ‡ä¸Šéƒ½è¡¨ç°ä¼˜å¼‚ï¼Œç‰¹åˆ«æ˜¯æ•æ„Ÿæ€§å’Œç‰¹å¼‚æ€§çš„å¹³è¡¡

### ğŸ“Š æ€§èƒ½åˆ†æ
1. **å‡†ç¡®ç‡èŒƒå›´**: {df['Accuracy'].min():.2f}% - {df['Accuracy'].max():.2f}%
2. **å¹³å‡å‡†ç¡®ç‡**: {df['Accuracy'].mean():.2f}%
3. **æ ‡å‡†å·®**: {df['Accuracy'].std():.2f}%

### ğŸ” æ¨¡å‹ç‰¹ç‚¹åˆ†æ

#### ä¼ ç»ŸCNNæ¶æ„
- **ResNet18-Improved**: æœ€ä½³æ•´ä½“æ€§èƒ½ï¼Œæ”¹è¿›çš„æ®‹å·®è¿æ¥å’Œæ³¨æ„åŠ›æœºåˆ¶æ•ˆæœæ˜¾è‘—
- **EfficientNet-B0**: æ•ˆç‡ä¸æ€§èƒ½çš„è‰¯å¥½å¹³è¡¡ï¼Œè½»é‡çº§ä½†æ€§èƒ½ä¼˜ç§€
- **ConvNext-Tiny**: ç°ä»£CNNæ¶æ„ï¼Œæ€§èƒ½ç¨³å®š

#### Transformeræ¶æ„
- **ViT-Tiny**: Vision Transformeråœ¨å°å›¾åƒä¸Šçš„è¡¨ç°è‰¯å¥½
- **Micro-ViT**: é’ˆå¯¹MICæµ‹è¯•ä¼˜åŒ–çš„è½»é‡çº§Transformer

#### æ··åˆæ¶æ„
- **CoAtNet**: å·ç§¯+æ³¨æ„åŠ›çš„æ··åˆæ¶æ„
- **MIC_MobileNetV3**: ä¸“é—¨é’ˆå¯¹MICæµ‹è¯•ä¼˜åŒ–çš„ç§»åŠ¨ç«¯æ¶æ„
- **AirBubble_HybridNet**: ä¸“é—¨ç”¨äºæ°”æ³¡æ£€æµ‹çš„æ··åˆç½‘ç»œ

## æ¨èä½¿ç”¨åœºæ™¯

### ğŸ¯ ç”Ÿäº§ç¯å¢ƒæ¨è
1. **ResNet18-Improved**: æœ€é«˜å‡†ç¡®ç‡ï¼Œé€‚åˆå¯¹ç²¾åº¦è¦æ±‚æé«˜çš„åœºæ™¯
2. **EfficientNet-B0**: æ•ˆç‡ä¸æ€§èƒ½å¹³è¡¡ï¼Œé€‚åˆèµ„æºå—é™ç¯å¢ƒ

### ğŸ”¬ ç ”ç©¶å¼€å‘æ¨è
1. **MIC_MobileNetV3**: ä¸“é—¨ä¼˜åŒ–çš„æ¶æ„ï¼Œé€‚åˆè¿›ä¸€æ­¥ç ”ç©¶
2. **Micro-ViT**: Transformeræ¶æ„çš„æ¢ç´¢

## æŠ€æœ¯æ€»ç»“

### æˆåŠŸå› ç´ 
1. **æ•°æ®é¢„å¤„ç†**: ç»Ÿä¸€çš„70Ã—70åƒç´ æ ‡å‡†åŒ–
2. **æ¨¡å‹ä¼˜åŒ–**: é’ˆå¯¹å°å›¾åƒçš„æ¶æ„è°ƒæ•´
3. **è®­ç»ƒç­–ç•¥**: åˆé€‚çš„å­¦ä¹ ç‡å’Œæ­£åˆ™åŒ–

### æ”¹è¿›å»ºè®®
1. **æ•°æ®å¢å¼º**: å¯ä»¥è¿›ä¸€æ­¥æå‡æ¨¡å‹æ³›åŒ–èƒ½åŠ›
2. **é›†æˆå­¦ä¹ **: ç»“åˆå¤šä¸ªé«˜æ€§èƒ½æ¨¡å‹
3. **æ¨¡å‹å‹ç¼©**: é’ˆå¯¹ç§»åŠ¨ç«¯éƒ¨ç½²çš„è¿›ä¸€æ­¥ä¼˜åŒ–

---

*æœ¬æŠ¥å‘ŠåŸºäºå®Œæ•´çš„8ä¸ªæ¨¡å‹æµ‹è¯•ç»“æœç”Ÿæˆï¼Œæ‰€æœ‰æ¨¡å‹éƒ½åœ¨ç›¸åŒçš„æµ‹è¯•é›†ä¸Šè¿›è¡Œäº†è¯„ä¼°ã€‚*
"""
    
    # ä¿å­˜æŠ¥å‘Š
    with open('reports/final_complete_analysis.md', 'w', encoding='utf-8') as f:
        f.write(report)
    
    print("âœ… å®Œæ•´åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ:")
    print("  - reports/final_complete_analysis.md")
    print("  - reports/final_performance_comparison.png")
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ‰ ç”Ÿæˆæœ€ç»ˆå®Œæ•´åˆ†ææŠ¥å‘Š...")
    
    # ç¡®ä¿reportsç›®å½•å­˜åœ¨
    os.makedirs('reports', exist_ok=True)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = generate_detailed_report()
    
    print("\n" + "="*60)
    print("ğŸ† æ‰€æœ‰8ä¸ªæ¨¡å‹æµ‹è¯•å®Œæˆ!")
    print("ğŸ“Š æ€§èƒ½åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ!")
    print("="*60)

if __name__ == "__main__":
    main()