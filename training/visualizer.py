"""
è®­ç»ƒå¯è§†åŒ–æ¨¡å—
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Optional, Tuple
import os
from PIL import Image
import cv2

class TrainingVisualizer:
    """è®­ç»ƒè¿‡ç¨‹å¯è§†åŒ–å™¨"""
    
    def __init__(self, save_dir: str = './visualizations'):
        """
        Args:
            save_dir: å¯è§†åŒ–ç»“æœä¿å­˜ç›®å½•
        """
        self.save_dir = save_dir
        os.makedirs(save_dir, exist_ok=True)
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“ï¼Œä¸evaluator.pyä¿æŒä¸€è‡´
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        # è®¾ç½®é»˜è®¤å­—ä½“å¤§å°
        plt.rcParams['font.size'] = 10
    
    def plot_training_history(self, history: Dict[str, List[float]], 
                            model_name: str = 'Model'):
        """ç»˜åˆ¶è®­ç»ƒå†å²æ›²çº¿"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'{model_name} è®­ç»ƒå†å²', fontsize=16, fontweight='bold')
        
        epochs = range(1, len(history['train_loss']) + 1)
        
        # 1. æŸå¤±æ›²çº¿
        ax1 = axes[0, 0]
        ax1.plot(epochs, history['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
        ax1.plot(epochs, history['val_loss'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
        ax1.set_title('æŸå¤±æ›²çº¿')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. å‡†ç¡®ç‡æ›²çº¿
        ax2 = axes[0, 1]
        ax2.plot(epochs, history['train_acc'], 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
        ax2.plot(epochs, history['val_acc'], 'r-', label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)
        ax2.set_title('å‡†ç¡®ç‡æ›²çº¿')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. å­¦ä¹ ç‡æ›²çº¿
        ax3 = axes[1, 0]
        ax3.plot(epochs, history['lr'], 'g-', linewidth=2)
        ax3.set_title('å­¦ä¹ ç‡å˜åŒ–')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('Learning Rate')
        ax3.set_yscale('log')
        ax3.grid(True, alpha=0.3)
        
        # 4. è®­ç»ƒvséªŒè¯æ€§èƒ½å·®å¼‚
        ax4 = axes[1, 1]
        train_val_loss_diff = [t - v for t, v in zip(history['train_loss'], history['val_loss'])]
        train_val_acc_diff = [v - t for t, v in zip(history['train_acc'], history['val_acc'])]
        
        ax4.plot(epochs, train_val_loss_diff, 'purple', label='æŸå¤±å·®å¼‚ (è®­ç»ƒ-éªŒè¯)', linewidth=2)
        ax4_twin = ax4.twinx()
        ax4_twin.plot(epochs, train_val_acc_diff, 'orange', label='å‡†ç¡®ç‡å·®å¼‚ (éªŒè¯-è®­ç»ƒ)', linewidth=2)
        
        ax4.set_title('è¿‡æ‹Ÿåˆç›‘æ§')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('æŸå¤±å·®å¼‚', color='purple')
        ax4_twin.set_ylabel('å‡†ç¡®ç‡å·®å¼‚', color='orange')
        ax4.grid(True, alpha=0.3)
        
        # æ·»åŠ å›¾ä¾‹
        lines1, labels1 = ax4.get_legend_handles_labels()
        lines2, labels2 = ax4_twin.get_legend_handles_labels()
        ax4.legend(lines1 + lines2, labels1 + labels2, loc='upper left')
        
        plt.tight_layout()
        save_path = os.path.join(self.save_dir, f'{model_name}_training_history.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"è®­ç»ƒå†å²å›¾è¡¨å·²ä¿å­˜: {save_path}")
    
    def visualize_feature_maps(self, model: nn.Module, sample_images: torch.Tensor, 
                             labels: torch.Tensor, device: torch.device,
                             model_name: str = 'Model'):
        """å¯è§†åŒ–ç‰¹å¾å›¾"""
        
        model.eval()
        sample_images = sample_images.to(device)
        
        with torch.no_grad():
            # è·å–ç‰¹å¾å›¾
            if hasattr(model, 'get_feature_maps'):
                features = model.get_feature_maps(sample_images)
            else:
                print("æ¨¡å‹ä¸æ”¯æŒç‰¹å¾å›¾æå–")
                return
        
        # é€‰æ‹©å‡ ä¸ªä»£è¡¨æ€§çš„ç‰¹å¾å›¾å±‚
        selected_features = features[::2]  # æ¯éš”ä¸€å±‚é€‰æ‹©
        if len(selected_features) > 6:
            selected_features = selected_features[:6]
        
        num_samples = min(4, sample_images.size(0))
        num_layers = len(selected_features)
        
        fig, axes = plt.subplots(num_samples, num_layers + 1, 
                               figsize=(3 * (num_layers + 1), 3 * num_samples))
        fig.suptitle(f'{model_name} ç‰¹å¾å›¾å¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        for sample_idx in range(num_samples):
            # åŸå§‹å›¾åƒ
            ax = axes[sample_idx, 0] if num_samples > 1 else axes[0]
            original_img = sample_images[sample_idx].cpu()
            # åå½’ä¸€åŒ–
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
            original_img = original_img * std + mean
            original_img = torch.clamp(original_img, 0, 1)
            
            ax.imshow(original_img.permute(1, 2, 0))
            ax.set_title(f'åŸå›¾ (æ ‡ç­¾: {labels[sample_idx].item()})')
            ax.axis('off')
            
            # ç‰¹å¾å›¾
            for layer_idx, (layer_name, feature_map) in enumerate(selected_features):
                ax = axes[sample_idx, layer_idx + 1] if num_samples > 1 else axes[layer_idx + 1]
                
                # å–ç¬¬ä¸€ä¸ªé€šé“æˆ–å¹³å‡æ‰€æœ‰é€šé“
                feat = feature_map[sample_idx]
                if feat.dim() == 3:  # [C, H, W]
                    feat = feat.mean(dim=0)  # å¹³å‡æ‰€æœ‰é€šé“
                
                feat = feat.cpu().numpy()
                
                im = ax.imshow(feat, cmap='viridis')
                ax.set_title(f'{layer_name}\n{feat.shape}')
                ax.axis('off')
                
                # æ·»åŠ é¢œè‰²æ¡
                plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)
        
        plt.tight_layout()
        save_path = os.path.join(self.save_dir, f'{model_name}_feature_maps.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"ç‰¹å¾å›¾å¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    
    def visualize_grad_cam(self, model: nn.Module, sample_images: torch.Tensor,
                          labels: torch.Tensor, device: torch.device,
                          target_layer: str = 'layer4', model_name: str = 'Model'):
        """Grad-CAMå¯è§†åŒ–"""
        
        try:
            from pytorch_grad_cam import GradCAM
            from pytorch_grad_cam.utils.image import show_cam_on_image
        except ImportError:
            print("éœ€è¦å®‰è£… pytorch-grad-cam: pip install grad-cam")
            return
        
        model.eval()
        sample_images = sample_images.to(device)
        
        # æ‰¾åˆ°ç›®æ ‡å±‚
        target_layers = []
        for name, module in model.named_modules():
            if target_layer in name:
                target_layers.append(module)
                break
        
        if not target_layers:
            print(f"æœªæ‰¾åˆ°ç›®æ ‡å±‚: {target_layer}")
            return
        
        # åˆ›å»ºGradCAM
        cam = GradCAM(model=model, target_layers=target_layers)
        
        num_samples = min(4, sample_images.size(0))
        fig, axes = plt.subplots(2, num_samples, figsize=(4 * num_samples, 8))
        fig.suptitle(f'{model_name} Grad-CAMå¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        for i in range(num_samples):
            # åŸå§‹å›¾åƒ
            input_tensor = sample_images[i:i+1]
            
            # åå½’ä¸€åŒ–ç”¨äºæ˜¾ç¤º
            original_img = sample_images[i].cpu()
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
            original_img = original_img * std + mean
            original_img = torch.clamp(original_img, 0, 1)
            original_img_np = original_img.permute(1, 2, 0).numpy()
            
            # ç”ŸæˆCAM
            grayscale_cam = cam(input_tensor=input_tensor, targets=None)
            grayscale_cam = grayscale_cam[0, :]
            
            # å åŠ CAM
            visualization = show_cam_on_image(original_img_np, grayscale_cam, use_rgb=True)
            
            # æ˜¾ç¤ºåŸå›¾
            ax1 = axes[0, i] if num_samples > 1 else axes[0]
            ax1.imshow(original_img_np)
            ax1.set_title(f'åŸå›¾ {i+1}\næ ‡ç­¾: {labels[i].item()}')
            ax1.axis('off')
            
            # æ˜¾ç¤ºCAM
            ax2 = axes[1, i] if num_samples > 1 else axes[1]
            ax2.imshow(visualization)
            ax2.set_title(f'Grad-CAM {i+1}')
            ax2.axis('off')
        
        plt.tight_layout()
        save_path = os.path.join(self.save_dir, f'{model_name}_grad_cam.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"Grad-CAMå¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    
    def plot_model_comparison(self, models_history: Dict[str, Dict[str, List[float]]]):
        """æ¯”è¾ƒå¤šä¸ªæ¨¡å‹çš„è®­ç»ƒå†å²"""
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle('å¤šæ¨¡å‹è®­ç»ƒå¯¹æ¯”', fontsize=16, fontweight='bold')
        
        colors = plt.cm.tab10(np.linspace(0, 1, len(models_history)))
        
        # 1. è®­ç»ƒæŸå¤±å¯¹æ¯”
        ax1 = axes[0, 0]
        for (model_name, history), color in zip(models_history.items(), colors):
            epochs = range(1, len(history['train_loss']) + 1)
            ax1.plot(epochs, history['train_loss'], color=color, 
                    label=f'{model_name} è®­ç»ƒ', linewidth=2, alpha=0.8)
            ax1.plot(epochs, history['val_loss'], color=color, 
                    label=f'{model_name} éªŒè¯', linewidth=2, linestyle='--', alpha=0.8)
        
        ax1.set_title('è®­ç»ƒæŸå¤±å¯¹æ¯”')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('Loss')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”
        ax2 = axes[0, 1]
        for (model_name, history), color in zip(models_history.items(), colors):
            epochs = range(1, len(history['val_acc']) + 1)
            ax2.plot(epochs, history['val_acc'], color=color, 
                    label=model_name, linewidth=2, alpha=0.8)
        
        ax2.set_title('éªŒè¯å‡†ç¡®ç‡å¯¹æ¯”')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('Accuracy')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. æœ€ç»ˆæ€§èƒ½å¯¹æ¯”
        ax3 = axes[1, 0]
        model_names = list(models_history.keys())
        final_train_acc = [history['train_acc'][-1] for history in models_history.values()]
        final_val_acc = [history['val_acc'][-1] for history in models_history.values()]
        
        x = np.arange(len(model_names))
        width = 0.35
        
        ax3.bar(x - width/2, final_train_acc, width, label='è®­ç»ƒå‡†ç¡®ç‡', alpha=0.8)
        ax3.bar(x + width/2, final_val_acc, width, label='éªŒè¯å‡†ç¡®ç‡', alpha=0.8)
        
        ax3.set_title('æœ€ç»ˆæ€§èƒ½å¯¹æ¯”')
        ax3.set_xlabel('æ¨¡å‹')
        ax3.set_ylabel('å‡†ç¡®ç‡')
        ax3.set_xticks(x)
        ax3.set_xticklabels(model_names, rotation=45)
        ax3.legend()
        ax3.set_ylim([0, 1])
        
        # 4. æ”¶æ•›é€Ÿåº¦å¯¹æ¯”
        ax4 = axes[1, 1]
        for (model_name, history), color in zip(models_history.items(), colors):
            # è®¡ç®—è¾¾åˆ°90%æœ€ä½³éªŒè¯å‡†ç¡®ç‡æ‰€éœ€çš„epochæ•°
            best_val_acc = max(history['val_acc'])
            target_acc = 0.9 * best_val_acc
            
            convergence_epoch = len(history['val_acc'])
            for i, acc in enumerate(history['val_acc']):
                if acc >= target_acc:
                    convergence_epoch = i + 1
                    break
            
            ax4.bar(model_name, convergence_epoch, color=color, alpha=0.8)
        
        ax4.set_title('æ”¶æ•›é€Ÿåº¦å¯¹æ¯” (è¾¾åˆ°90%æœ€ä½³æ€§èƒ½)')
        ax4.set_xlabel('æ¨¡å‹')
        ax4.set_ylabel('æ‰€éœ€Epochæ•°')
        ax4.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        save_path = os.path.join(self.save_dir, 'models_comparison.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"æ¨¡å‹å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜: {save_path}")
    
    def visualize_predictions(self, model: nn.Module, data_loader, device: torch.device,
                            num_samples: int = 16, model_name: str = 'Model'):
        """å¯è§†åŒ–æ¨¡å‹é¢„æµ‹ç»“æœ"""
        
        model.eval()
        
        # æ”¶é›†æ ·æœ¬
        images_list = []
        labels_list = []
        predictions_list = []
        probabilities_list = []
        
        with torch.no_grad():
            for images, labels in data_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                probabilities = torch.softmax(outputs, dim=1)
                _, predictions = torch.max(outputs, 1)
                
                images_list.append(images.cpu())
                labels_list.append(labels.cpu())
                predictions_list.append(predictions.cpu())
                probabilities_list.append(probabilities.cpu())
                
                if len(images_list) * images.size(0) >= num_samples:
                    break
        
        # åˆå¹¶æ•°æ®
        all_images = torch.cat(images_list, dim=0)[:num_samples]
        all_labels = torch.cat(labels_list, dim=0)[:num_samples]
        all_predictions = torch.cat(predictions_list, dim=0)[:num_samples]
        all_probabilities = torch.cat(probabilities_list, dim=0)[:num_samples]
        
        # åˆ›å»ºå¯è§†åŒ–
        cols = 4
        rows = (num_samples + cols - 1) // cols
        
        fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows))
        fig.suptitle(f'{model_name} é¢„æµ‹ç»“æœå¯è§†åŒ–', fontsize=16, fontweight='bold')
        
        class_names = ['negative', 'positive']
        
        for i in range(num_samples):
            row, col = divmod(i, cols)
            ax = axes[row, col] if rows > 1 else axes[col]
            
            # åå½’ä¸€åŒ–å›¾åƒ
            img = all_images[i]
            mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)
            std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)
            img = img * std + mean
            img = torch.clamp(img, 0, 1)
            
            ax.imshow(img.permute(1, 2, 0))
            
            # æ ‡é¢˜ä¿¡æ¯
            true_label = class_names[all_labels[i].item()]
            pred_label = class_names[all_predictions[i].item()]
            confidence = all_probabilities[i].max().item()
            
            # æ ¹æ®é¢„æµ‹æ­£ç¡®æ€§è®¾ç½®é¢œè‰²
            color = 'green' if all_labels[i] == all_predictions[i] else 'red'
            
            ax.set_title(f'çœŸå®: {true_label}\né¢„æµ‹: {pred_label}\nç½®ä¿¡åº¦: {confidence:.3f}',
                        color=color, fontweight='bold')
            ax.axis('off')
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(num_samples, rows * cols):
            row, col = divmod(i, cols)
            ax = axes[row, col] if rows > 1 else axes[col]
            ax.axis('off')
        
        plt.tight_layout()
        save_path = os.path.join(self.save_dir, f'{model_name}_predictions.png')
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        print(f"é¢„æµ‹ç»“æœå¯è§†åŒ–å·²ä¿å­˜: {save_path}")
    
    def create_training_summary(self, models_results: Dict[str, Dict], 
                              models_history: Dict[str, Dict[str, List[float]]]):
        """åˆ›å»ºè®­ç»ƒæ€»ç»“æŠ¥å‘Š"""
        
        # åˆ›å»ºHTMLæŠ¥å‘Š
        html_content = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>æ¨¡å‹è®­ç»ƒæ€»ç»“æŠ¥å‘Š</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 40px; }
                .header { text-align: center; color: #333; }
                .section { margin: 30px 0; }
                .model-card { 
                    border: 1px solid #ddd; 
                    border-radius: 8px; 
                    padding: 20px; 
                    margin: 20px 0; 
                    background-color: #f9f9f9;
                }
                .metric { display: inline-block; margin: 10px 20px; }
                .metric-value { font-weight: bold; color: #2196F3; }
                table { border-collapse: collapse; width: 100%; }
                th, td { border: 1px solid #ddd; padding: 8px; text-align: center; }
                th { background-color: #f2f2f2; }
                .best { background-color: #e8f5e8; }
            </style>
        </head>
        <body>
            <div class="header">
                <h1>ç”Ÿç‰©æŠ—èŒç´ æ•æ„Ÿæ€§æµ‹è¯• - æ¨¡å‹è®­ç»ƒæ€»ç»“æŠ¥å‘Š</h1>
                <p>èŒè½æ£€æµ‹äºŒåˆ†ç±»ä»»åŠ¡</p>
            </div>
        """
        
        # æ·»åŠ æ¨¡å‹å¯¹æ¯”è¡¨
        html_content += """
            <div class="section">
                <h2>æ¨¡å‹æ€§èƒ½å¯¹æ¯”</h2>
                <table>
                    <tr>
                        <th>æ¨¡å‹</th>
                        <th>å‡†ç¡®ç‡</th>
                        <th>ç²¾ç¡®ç‡</th>
                        <th>å¬å›ç‡</th>
                        <th>F1åˆ†æ•°</th>
                        <th>AUC</th>
                        <th>æ•æ„Ÿæ€§</th>
                        <th>ç‰¹å¼‚æ€§</th>
                    </tr>
        """
        
        # æ‰¾åˆ°æœ€ä½³æ¨¡å‹
        best_model = max(models_results.items(), key=lambda x: x[1]['accuracy'])
        
        for model_name, results in models_results.items():
            is_best = model_name == best_model[0]
            row_class = 'best' if is_best else ''
            
            html_content += f"""
                    <tr class="{row_class}">
                        <td><strong>{model_name}</strong></td>
                        <td>{results['accuracy']:.4f}</td>
                        <td>{results['precision']:.4f}</td>
                        <td>{results['recall']:.4f}</td>
                        <td>{results['f1_score']:.4f}</td>
                        <td>{results['auc']:.4f}</td>
                        <td>{results['sensitivity']:.4f}</td>
                        <td>{results['specificity']:.4f}</td>
                    </tr>
            """
        
        html_content += """
                </table>
                <p><em>ç»¿è‰²èƒŒæ™¯è¡¨ç¤ºæœ€ä½³æ¨¡å‹</em></p>
            </div>
        """
        
        # æ·»åŠ è¯¦ç»†åˆ†æ
        html_content += """
            <div class="section">
                <h2>è¯¦ç»†åˆ†æ</h2>
        """
        
        for model_name, results in models_results.items():
            is_best = model_name == best_model[0]
            
            html_content += f"""
                <div class="model-card">
                    <h3>{model_name} {'ğŸ† (æœ€ä½³æ¨¡å‹)' if is_best else ''}</h3>
                    <div class="metric">
                        <span>å‡†ç¡®ç‡:</span> 
                        <span class="metric-value">{results['accuracy']:.4f}</span>
                    </div>
                    <div class="metric">
                        <span>AUC:</span> 
                        <span class="metric-value">{results['auc']:.4f}</span>
                    </div>
                    <div class="metric">
                        <span>æ•æ„Ÿæ€§:</span> 
                        <span class="metric-value">{results['sensitivity']:.4f}</span>
                    </div>
                    <div class="metric">
                        <span>ç‰¹å¼‚æ€§:</span> 
                        <span class="metric-value">{results['specificity']:.4f}</span>
                    </div>
                    
                    <h4>æ··æ·†çŸ©é˜µ</h4>
                    <table style="width: 300px;">
                        <tr><th></th><th>é¢„æµ‹ Negative</th><th>é¢„æµ‹ Positive</th></tr>
                        <tr><th>çœŸå® Negative</th><td>{results['confusion_matrix'][0][0]}</td><td>{results['confusion_matrix'][0][1]}</td></tr>
                        <tr><th>çœŸå® Positive</th><td>{results['confusion_matrix'][1][0]}</td><td>{results['confusion_matrix'][1][1]}</td></tr>
                    </table>
                </div>
            """
        
        html_content += """
            </div>
            
            <div class="section">
                <h2>è®­ç»ƒå»ºè®®</h2>
                <ul>
                    <li>æ•°æ®é›†ç›¸å¯¹å¹³è¡¡ï¼Œæ­£è´Ÿæ ·æœ¬æ¯”ä¾‹ä¸º 2910:2401</li>
                    <li>å›¾åƒå°ºå¯¸ä¸º70x70ï¼Œé€‚åˆè½»é‡çº§æ¨¡å‹</li>
                    <li>æ­£æ ·æœ¬(èŒè½)åƒç´ å€¼è¾ƒæš—(å‡å€¼151.8)ï¼Œè´Ÿæ ·æœ¬è¾ƒäº®(å‡å€¼245.1)</li>
                    <li>å»ºè®®ä½¿ç”¨æ•°æ®å¢å¼ºæŠ€æœ¯æé«˜æ¨¡å‹æ³›åŒ–èƒ½åŠ›</li>
                    <li>å¯ä»¥å°è¯•é›†æˆå­¦ä¹ æ–¹æ³•è¿›ä¸€æ­¥æå‡æ€§èƒ½</li>
                </ul>
            </div>
            
        </body>
        </html>
        """
        
        # ä¿å­˜HTMLæŠ¥å‘Š
        report_path = os.path.join(self.save_dir, 'training_summary_report.html')
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"è®­ç»ƒæ€»ç»“æŠ¥å‘Šå·²ä¿å­˜: {report_path}")

if __name__ == "__main__":
    # æµ‹è¯•å¯è§†åŒ–å™¨
    visualizer = TrainingVisualizer('./test_visualizations')
    
    # æ¨¡æ‹Ÿè®­ç»ƒå†å²
    history = {
        'train_loss': [0.8, 0.6, 0.4, 0.3, 0.2],
        'val_loss': [0.7, 0.5, 0.4, 0.35, 0.3],
        'train_acc': [0.6, 0.7, 0.8, 0.85, 0.9],
        'val_acc': [0.65, 0.75, 0.8, 0.82, 0.85],
        'lr': [0.001, 0.001, 0.0005, 0.0002, 0.0001]
    }
    
    visualizer.plot_training_history(history, 'TestModel')
    print("å¯è§†åŒ–æµ‹è¯•å®Œæˆ")
