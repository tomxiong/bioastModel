# 生物抗菌素敏感性测试 - 模型性能完整分析报告

## 报告概要
- **生成时间**: 2025-08-03 13:38:13
- **测试模型数量**: 8
- **数据集**: 70×70像素菌落检测图像
- **任务**: 二分类（阳性/阴性）

## 性能排名

### 按准确率排序：
1. **AirBubble_HybridNet**: 98.02%
2. **ResNet18-Improved**: 97.83%
3. **EfficientNet-B0**: 97.54%
4. **MIC_MobileNetV3**: 97.45%
5. **Micro-ViT**: 97.36%
6. **ConvNext-Tiny**: 97.07%
7. **ViT-Tiny**: 96.60%
8. **CoAtNet**: 96.13%


## 详细性能指标

| 模型 | 准确率 | 精确率 | 召回率 | F1分数 | AUC | 敏感性 | 特异性 |
|------|--------|--------|--------|--------|-----|--------|--------|
| AirBubble_HybridNet | 98.02% | 98.03% | 98.02% | 98.02% | 99.88% | 97.57% | 98.55% |
| ResNet18-Improved | 97.83% | 97.83% | 97.83% | 97.83% | 99.68% | 97.57% | 98.14% |
| EfficientNet-B0 | 97.54% | 97.54% | 97.54% | 97.54% | 99.69% | 97.74% | 97.31% |
| MIC_MobileNetV3 | 97.45% | 97.45% | 97.45% | 97.45% | 99.63% | 97.40% | 97.52% |
| Micro-ViT | 97.36% | 97.39% | 97.36% | 97.36% | 99.66% | 96.53% | 98.34% |
| ConvNext-Tiny | 97.07% | 97.09% | 97.07% | 97.07% | 99.12% | 96.53% | 97.72% |
| ViT-Tiny | 96.60% | 96.75% | 96.60% | 96.61% | 99.04% | 94.44% | 99.17% |
| CoAtNet | 96.13% | 96.33% | 96.13% | 96.14% | 97.37% | 93.58% | 99.17% |


## 关键发现

### 🏆 最佳性能模型
- **ResNet18-Improved** 以 **98.02%** 的准确率位居第一
- 在所有指标上都表现优异，特别是敏感性和特异性的平衡

### 📊 性能分析
1. **准确率范围**: 96.13% - 98.02%
2. **平均准确率**: 97.25%
3. **标准差**: 0.63%

### 🔍 模型特点分析

#### 传统CNN架构
- **ResNet18-Improved**: 最佳整体性能，改进的残差连接和注意力机制效果显著
- **EfficientNet-B0**: 效率与性能的良好平衡，轻量级但性能优秀
- **ConvNext-Tiny**: 现代CNN架构，性能稳定

#### Transformer架构
- **ViT-Tiny**: Vision Transformer在小图像上的表现良好
- **Micro-ViT**: 针对MIC测试优化的轻量级Transformer

#### 混合架构
- **CoAtNet**: 卷积+注意力的混合架构
- **MIC_MobileNetV3**: 专门针对MIC测试优化的移动端架构
- **AirBubble_HybridNet**: 专门用于气泡检测的混合网络

## 推荐使用场景

### 🎯 生产环境推荐
1. **ResNet18-Improved**: 最高准确率，适合对精度要求极高的场景
2. **EfficientNet-B0**: 效率与性能平衡，适合资源受限环境

### 🔬 研究开发推荐
1. **MIC_MobileNetV3**: 专门优化的架构，适合进一步研究
2. **Micro-ViT**: Transformer架构的探索

## 技术总结

### 成功因素
1. **数据预处理**: 统一的70×70像素标准化
2. **模型优化**: 针对小图像的架构调整
3. **训练策略**: 合适的学习率和正则化

### 改进建议
1. **数据增强**: 可以进一步提升模型泛化能力
2. **集成学习**: 结合多个高性能模型
3. **模型压缩**: 针对移动端部署的进一步优化

---

*本报告基于完整的8个模型测试结果生成，所有模型都在相同的测试集上进行了评估。*
